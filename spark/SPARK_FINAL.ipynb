{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpyyNkT4rsZT"
      },
      "source": [
        "# **UnB/ESW/PSPD - Laboratório2 sobre Spark Streaming**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_A4TOivc6gBd"
      },
      "source": [
        "# 1 Inicializações para o laboratório\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8yWG-Zpa4O2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99d85ded-a7bf-4ac9-d136-94b104e86cb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.20.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2025.10.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "# Instalando a biblioteca que permite copiar conteúdos do Gdrive compartilhado do professor\n",
        "!pip install gdown\n",
        "import gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rBrMXirdq6Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66321fe8-4f78-4410-df93-ca072f5ac6a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 1iCUcvpU6aWAZy2muCrvMwLxkDNVhwlgO confluentinc-kafka-connect-elasticsearch-14.0.10.zip\n",
            "Processing file 1spWo1lFBOPE8r-i2mqEpIi072lm8rqAo connect.properties\n",
            "Processing file 1YyzYe69OlCcGLrVvAbwefxJmcle4GVyA elastic.properties\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1iCUcvpU6aWAZy2muCrvMwLxkDNVhwlgO\n",
            "From (redirected): https://drive.google.com/uc?id=1iCUcvpU6aWAZy2muCrvMwLxkDNVhwlgO&confirm=t&uuid=2dc170d7-43be-41e8-8ff9-dd760182df5b\n",
            "To: /content/LabElastic/confluentinc-kafka-connect-elasticsearch-14.0.10.zip\n",
            "100%|██████████| 41.0M/41.0M [00:00<00:00, 93.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1spWo1lFBOPE8r-i2mqEpIi072lm8rqAo\n",
            "To: /content/LabElastic/connect.properties\n",
            "100%|██████████| 571/571 [00:00<00:00, 1.88MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1YyzYe69OlCcGLrVvAbwefxJmcle4GVyA\n",
            "To: /content/LabElastic/elastic.properties\n",
            "100%|██████████| 425/425 [00:00<00:00, 1.87MB/s]\n",
            "Download completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/LabElastic/confluentinc-kafka-connect-elasticsearch-14.0.10.zip',\n",
              " '/content/LabElastic/connect.properties',\n",
              " '/content/LabElastic/elastic.properties']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Copiando a pasta de laboratório (material do professor) para o contexto do aluno\n",
        "url = 'https://drive.google.com/drive/folders/1z_l8RO6YYwjLdPrMBtnSNpfzfznJt1ja'\n",
        "gdown.download_folder(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LykXc0FX25P"
      },
      "source": [
        "#2 Instalando o Spark - versão cluster\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKgAI05zl6Bx"
      },
      "outputs": [],
      "source": [
        "# Definindo as variáveis de ambiente do Spark (e do Hadoop?)\n",
        "import os\n",
        "# Variáveis gerais\n",
        "os.environ['JAVA_HOME']=\"/usr/lib/jvm/java-11-openjdk-amd64\" # readlink -f /usr/bin/javac\n",
        "os.environ['BASHRC_PATH']= \"/root/.bashrc\"\n",
        "# Variáveis específicas do Spark\n",
        "os.environ['SPARK_INSTALL_DIR']=\"/content\"\n",
        "os.environ['SPARK_HOME']=\"/content/spark\"\n",
        "# Seu PYSPARK_SUBMIT_ARGS atual + o conector do Elasticsearch (versão 8.15.0)\n",
        "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-10_2.12:3.5.0,org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.elasticsearch:elasticsearch-spark-30_2.12:8.15.0 pyspark-shell'\n",
        "# Adicione: org.elasticsearch:elasticsearch-spark-30_2.12:7.12.0\n",
        "#os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-10_2.12:3.5.0,org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.elasticsearch:elasticsearch-spark-30_2.12:7.12.0 pyspark-shell'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!java -version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "romaOwDKBtx7",
        "outputId": "8808a15b-315c-428a-9191-5efc05614916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk version \"17.0.16\" 2025-07-15\n",
            "OpenJDK Runtime Environment (build 17.0.16+8-Ubuntu-0ubuntu122.04.1)\n",
            "OpenJDK 64-Bit Server VM (build 17.0.16+8-Ubuntu-0ubuntu122.04.1, mixed mode, sharing)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_Mr_4l8E8vz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ad9500e-7d8f-4ef3-97a0-7a266330bf02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-15 20:41:04--  https://archive.apache.org/dist/spark/spark-3.5.6/spark-3.5.6-bin-hadoop3.tgz\n",
            "Resolving archive.apache.org (archive.apache.org)... 65.108.204.189, 2a01:4f9:1a:a084::2\n",
            "Connecting to archive.apache.org (archive.apache.org)|65.108.204.189|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 400923510 (382M) [application/x-gzip]\n",
            "Saving to: ‘/content/spark-3.5.6-bin-hadoop3.tgz’\n",
            "\n",
            "spark-3.5.6-bin-had 100%[===================>] 382.35M  2.50MB/s    in 69s     \n",
            "\n",
            "2025-11-15 20:42:14 (5.57 MB/s) - ‘/content/spark-3.5.6-bin-hadoop3.tgz’ saved [400923510/400923510]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Copiando os fonte do hadoop para a pasta $SPARK_INSTALL_DIR\n",
        "!wget https://archive.apache.org/dist/spark/spark-3.5.6/spark-3.5.6-bin-hadoop3.tgz -P $SPARK_INSTALL_DIR"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3AE0prwnBeOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NScGcZUwIlTA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "356ffae6-c82d-42b8-fe2e-388da8f3ac87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spark-3.5.6-bin-hadoop3/\n",
            "spark-3.5.6-bin-hadoop3/examples/\n",
            "spark-3.5.6-bin-hadoop3/examples/jars/\n",
            "spark-3.5.6-bin-hadoop3/examples/jars/spark-examples_2.12-3.5.6.jar\n",
            "spark-3.5.6-bin-hadoop3/examples/jars/scopt_2.12-3.7.1.jar\n",
            "spark-3.5.6-bin-hadoop3/examples/src/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaTC.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVarianceThresholdSelectorExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaUnivariateFeatureSelectorExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFMRegressorExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFMClassifierExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRobustScalerExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/hive/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedScalar.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredComplexSessionization.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKerberizedKafkaWordCount.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKerberizedKafkaWordCount.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/AgeExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithLoader.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/SparkSessionExtensionsTest.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithoutLoader.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RobustScalerExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FMRegressorExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VarianceThresholdSelectorExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FMClassifierExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/UnivariateFeatureSelectorExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/SimpleTypedAggregator.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedScalar.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/hive/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/ExampleJdbcConnectionProvider.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredComplexSessionization.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKerberizedKafkaWordCount.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/AccumulatorMetricsTest.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/pythonconverters/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/MiniReadWriteTest.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKerberizedKafkaWordCount.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scripts/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/scripts/getGpusResources.sh\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/r/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/r/data-manipulation.R\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/r/RSparkSQLExample.R\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/r/ml/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/r/ml/kstest.R\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/r/ml/fmRegressor.R\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/r/ml/naiveBayes.R\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/r/ml/kmeans.R\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/r/ml/fmClassifier.R\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/r/ml/als.R\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/r/ml/fpm.R\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/r/ml/decisionTree.R\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/r/ml/lm_with_elastic_net.R\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/r/ml/randomForest.R\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/r/ml/survreg.R\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/r/ml/prefixSpan.R\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/r/ml/logit.R\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/r/ml/ml.R\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/r/ml/svmLinear.R\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/r/ml/bisectingKmeans.R\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/r/ml/powerIterationClustering.R\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/r/ml/gbt.R\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/r/ml/gaussianMixture.R\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/r/ml/lda.R\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/r/ml/mlp.R\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/r/ml/isoreg.R\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/r/ml/glm.R\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/r/dataframe.R\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/r/streaming/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/r/streaming/structured_network_wordcount.R\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/power_iteration_clustering_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/normalizer_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/stratified_sampling_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/streaming_linear_regression_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/elementwise_product_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/regression_metrics_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/streaming_k_means_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/svd_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/kernel_density_estimation_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/k_means_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/word2vec.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/hypothesis_testing_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/summary_statistics_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/fpgrowth_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/multi_class_metrics_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/gaussian_mixture_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/recommendation_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/pca_rowmatrix_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/correlations.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/svm_with_sgd_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/isotonic_regression_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/linear_regression_with_sgd_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/random_forest_regression_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/multi_label_metrics_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/word2vec_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/tf_idf_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/logistic_regression.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/decision_tree_regression_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/bisecting_k_means_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/random_forest_classification_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/sampled_rdds.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/gaussian_mixture_model.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/standard_scaler_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/random_rdd_generation.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/ranking_metrics_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/naive_bayes_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/gradient_boosting_classification_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/decision_tree_classification_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/gradient_boosting_regression_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/kmeans.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/binary_classification_metrics_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/mllib/correlations_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/parquet_inputformat.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/als.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/power_iteration_clustering_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/normalizer_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/pca_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/elementwise_product_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/n_gram_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/imputer_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/min_max_scaler_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/quantile_discretizer_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/count_vectorizer_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/vector_size_hint_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/vector_assembler_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/logistic_regression_with_elastic_net.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/binarizer_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/chi_square_test_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/cross_validator.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/linearsvc.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/pipeline_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/vector_indexer_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/string_indexer_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/fpgrowth_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/index_to_string_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/chisq_selector_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/dct_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/generalized_linear_regression_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/gaussian_mixture_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/bucketizer_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/tokenizer_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/fm_regressor_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/one_vs_rest_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/aft_survival_regression.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/lda_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/isotonic_regression_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/word2vec_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/tf_idf_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/dataframe_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/decision_tree_regression_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/bisecting_k_means_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/multilayer_perceptron_classification.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/train_validation_split.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/feature_hasher_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/random_forest_regressor_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/linear_regression_with_elastic_net.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/standard_scaler_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/__init__,py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/kmeans_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/logistic_regression_summary_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/summarizer_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/univariate_feature_selector_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/fm_classifier_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/estimator_transformer_param_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/prefixspan_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/rformula_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/variance_threshold_selector_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/correlation_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/naive_bayes_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/min_hash_lsh_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/onehot_encoder_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/interaction_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/max_abs_scaler_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/als_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/random_forest_classifier_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/decision_tree_classification_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/sql_transformer.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/stopwords_remover_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/vector_slicer_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/polynomial_expansion_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/ml/robust_scaler_example.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/sql/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/sql/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/sql/basic.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/sql/datasource.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/sql/arrow.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/sql/hive.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/sql/udtf.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/sql/streaming/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/sql/streaming/structured_network_wordcount_session_window.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/sql/streaming/structured_network_wordcount.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/sql/streaming/__init__,py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/sql/streaming/structured_sessionization.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/pi.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/logistic_regression.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/pagerank.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/sort.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/avro_inputformat.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/wordcount.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/streaming/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/streaming/queue_stream.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/streaming/recoverable_network_wordcount.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/streaming/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/streaming/sql_network_wordcount.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/streaming/hdfs_wordcount.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/streaming/network_wordcount.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/streaming/network_wordjoinsentiments.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/streaming/stateful_network_wordcount.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/transitive_closure.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/kmeans.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/python/status_api_demo.py\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/resources/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/resources/dir1/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/resources/dir1/file3.json\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/resources/dir1/file1.parquet\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/resources/dir1/dir2/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/resources/dir1/dir2/file2.parquet\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/resources/people.csv\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/resources/users.parquet\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/resources/employees.json\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/resources/people.json\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/resources/kv1.txt\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/resources/users.avro\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/resources/people.txt\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/resources/users.orc\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/resources/full_user.avsc\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/resources/META-INF/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/resources/META-INF/services/\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/resources/META-INF/services/org.apache.spark.sql.jdbc.JdbcConnectionProvider\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/resources/META-INF/services/org.apache.spark.sql.SparkSessionExtensionsProvider\n",
            "spark-3.5.6-bin-hadoop3/examples/src/main/resources/user.avsc\n",
            "spark-3.5.6-bin-hadoop3/RELEASE\n",
            "spark-3.5.6-bin-hadoop3/yarn/\n",
            "spark-3.5.6-bin-hadoop3/yarn/spark-3.5.6-yarn-shuffle.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/\n",
            "spark-3.5.6-bin-hadoop3/jars/avro-1.11.4.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/netty-transport-native-unix-common-4.1.96.Final.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/spark-yarn_2.12-3.5.6.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/zookeeper-jute-3.6.3.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/spire-macros_2.12-0.17.0.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/commons-lang-2.6.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/arrow-vector-12.0.1.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/kubernetes-model-resource-6.7.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/stream-2.9.6.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/chill-java-0.10.0.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/hadoop-yarn-server-web-proxy-3.3.4.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/kubernetes-model-flowcontrol-6.7.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/spark-core_2.12-3.5.6.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/bonecp-0.8.0.RELEASE.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/spark-unsafe_2.12-3.5.6.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/spark-sql-api_2.12-3.5.6.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/scala-parser-combinators_2.12-2.3.0.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/arrow-format-12.0.1.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/kubernetes-model-coordination-6.7.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/lz4-java-1.8.0.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/flatbuffers-java-1.12.0.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/kubernetes-model-discovery-6.7.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/ivy-2.5.1.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/jackson-datatype-jsr310-2.15.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/spire_2.12-0.17.0.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/parquet-encoding-1.13.1.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/netty-transport-native-epoll-4.1.96.Final-linux-aarch_64.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/datasketches-memory-2.1.0.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/scala-reflect-2.12.18.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/metrics-core-4.2.19.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/minlog-1.3.0.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/algebra_2.12-2.0.1.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/spark-network-common_2.12-3.5.6.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/leveldbjni-all-1.8.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/hadoop-client-runtime-3.3.4.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/orc-mapreduce-1.9.6-shaded-protobuf.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/breeze_2.12-2.1.0.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/logging-interceptor-3.12.12.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/jpam-1.1.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/metrics-json-4.2.19.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/netty-handler-4.1.96.Final.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/kubernetes-model-batch-6.7.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/json-1.8.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/aopalliance-repackaged-2.6.1.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/commons-io-2.16.1.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/arpack-3.0.3.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/oro-2.0.8.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/metrics-jvm-4.2.19.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/spark-streaming_2.12-3.5.6.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/super-csv-2.2.0.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/spark-sketch_2.12-3.5.6.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/hive-service-rpc-3.1.3.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/audience-annotations-0.5.0.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/commons-compress-1.23.0.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/mesos-1.4.3-shaded-protobuf.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/kubernetes-model-autoscaling-6.7.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/json4s-core_2.12-3.7.0-M11.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/jakarta.inject-2.6.1.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/log4j-1.2-api-2.20.0.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/chill_2.12-0.10.0.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/json4s-ast_2.12-3.7.0-M11.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/threeten-extra-1.7.1.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/kubernetes-model-scheduling-6.7.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/jcl-over-slf4j-2.0.7.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/hk2-api-2.6.1.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/spire-platform_2.12-0.17.0.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/curator-framework-2.13.0.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/cats-kernel_2.12-2.1.1.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/netty-resolver-4.1.96.Final.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/commons-logging-1.1.3.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/osgi-resource-locator-1.0.3.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/hive-shims-0.23-2.3.9.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/commons-math3-3.6.1.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/jersey-common-2.40.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/netty-codec-http2-4.1.96.Final.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/metrics-jmx-4.2.19.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/gson-2.2.4.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/kubernetes-model-gatewayapi-6.7.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/httpcore-4.4.16.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/commons-lang3-3.12.0.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/hive-shims-common-2.3.9.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/spark-kubernetes_2.12-3.5.6.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/hadoop-client-api-3.3.4.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/jakarta.ws.rs-api-2.1.6.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/orc-core-1.9.6-shaded-protobuf.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/commons-collections4-4.4.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/netty-transport-classes-epoll-4.1.96.Final.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/arrow-memory-core-12.0.1.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/jersey-hk2-2.40.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/spire-util_2.12-0.17.0.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/kubernetes-model-metrics-6.7.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/netty-transport-native-epoll-4.1.96.Final-linux-x86_64.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/kubernetes-model-extensions-6.7.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/netty-transport-4.1.96.Final.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/kryo-shaded-4.0.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/jackson-databind-2.15.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/spark-hive-thriftserver_2.12-3.5.6.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/jakarta.servlet-api-4.0.3.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/hive-metastore-2.3.9.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/objenesis-3.3.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/slf4j-api-2.0.7.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/jackson-mapper-asl-1.9.13.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/avro-ipc-1.11.4.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/hive-common-2.3.9.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/aircompressor-0.27.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/parquet-column-1.13.1.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/rocksdbjni-8.3.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/scala-xml_2.12-2.1.0.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/zjsonpatch-0.3.0.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/json4s-scalap_2.12-3.7.0-M11.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/ST4-4.0.4.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/snakeyaml-2.0.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/transaction-api-1.1.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/libthrift-0.12.0.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/httpclient-4.5.14.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/commons-pool-1.5.4.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/spark-hive_2.12-3.5.6.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/hadoop-shaded-guava-1.1.1.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/xbean-asm9-shaded-4.23.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/kubernetes-model-apiextensions-6.7.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/jersey-client-2.40.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/parquet-common-1.13.1.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/tink-1.9.0.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/JTransforms-3.1.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/snakeyaml-engine-2.6.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/istack-commons-runtime-3.0.8.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/netty-buffer-4.1.96.Final.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/log4j-slf4j2-impl-2.20.0.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/netty-codec-http-4.1.96.Final.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/jakarta.validation-api-2.0.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/hive-exec-2.3.9-core.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/netty-transport-classes-kqueue-4.1.96.Final.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/netty-codec-socks-4.1.96.Final.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/univocity-parsers-2.9.1.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/RoaringBitmap-0.9.45.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/snappy-java-1.1.10.5.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/kubernetes-model-rbac-6.7.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/kubernetes-client-api-6.7.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/blas-3.0.3.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/parquet-format-structures-1.13.1.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/kubernetes-model-certificates-6.7.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/joda-time-2.12.5.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/hive-storage-api-2.8.1.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/zookeeper-3.6.3.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/jakarta.annotation-api-1.3.5.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/netty-transport-native-kqueue-4.1.96.Final-osx-aarch_64.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/datasketches-java-3.3.0.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/javax.jdo-3.2.0-m3.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/hive-cli-2.3.9.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/kubernetes-model-core-6.7.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/jackson-annotations-2.15.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/metrics-graphite-4.2.19.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/hive-shims-scheduler-2.3.9.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/libfb303-0.9.3.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/janino-3.1.9.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/commons-compiler-3.1.9.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/hive-shims-2.3.9.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/spark-catalyst_2.12-3.5.6.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/kubernetes-model-networking-6.7.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/jodd-core-3.5.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/jackson-dataformat-yaml-2.15.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/commons-text-1.10.0.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/commons-crypto-1.1.0.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/okio-1.17.6.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/javassist-3.29.2-GA.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/kubernetes-model-node-6.7.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/zstd-jni-1.5.5-4.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/jta-1.1.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/netty-all-4.1.96.Final.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/okhttp-3.12.12.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/datanucleus-core-4.1.17.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/kubernetes-client-6.7.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/stax-api-1.0.1.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/jul-to-slf4j-2.0.7.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/antlr4-runtime-4.9.3.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/kubernetes-model-apps-6.7.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/spark-mllib_2.12-3.5.6.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/netty-codec-4.1.96.Final.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/jackson-core-2.15.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/spark-sql_2.12-3.5.6.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/antlr-runtime-3.5.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/curator-recipes-2.13.0.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/scala-collection-compat_2.12-2.7.0.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/scala-compiler-2.12.18.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/arpack_combined_all-0.1.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/jackson-core-asl-1.9.13.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/shims-0.9.45.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/curator-client-2.13.0.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/spark-launcher_2.12-3.5.6.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/jackson-module-scala_2.12-2.15.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/spark-mesos_2.12-3.5.6.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/javolution-5.5.1.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/kubernetes-model-storageclass-6.7.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/hive-beeline-2.3.9.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/commons-codec-1.16.1.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/py4j-0.10.9.7.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/kubernetes-model-events-6.7.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/JLargeArrays-1.5.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/derby-10.14.2.0.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/jline-2.14.6.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/kubernetes-httpclient-okhttp-6.7.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/xz-1.9.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/parquet-hadoop-1.13.1.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/spark-tags_2.12-3.5.6.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/log4j-api-2.20.0.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/spark-repl_2.12-3.5.6.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/opencsv-2.3.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/spark-kvstore_2.12-3.5.6.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/spark-mllib-local_2.12-3.5.6.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/avro-mapred-1.11.4.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/json4s-jackson_2.12-3.7.0-M11.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/kubernetes-model-admissionregistration-6.7.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/annotations-17.0.0.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/activation-1.1.1.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/log4j-core-2.20.0.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/hive-jdbc-2.3.9.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/jdo-api-3.0.1.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/pickle-1.3.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/netty-handler-proxy-4.1.96.Final.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/paranamer-2.8.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/jakarta.xml.bind-api-2.3.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/commons-collections-3.2.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/kubernetes-model-policy-6.7.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/hive-llap-common-2.3.9.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/HikariCP-2.5.1.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/kubernetes-model-common-6.7.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/jersey-server-2.40.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/jaxb-runtime-2.3.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/breeze-macros_2.12-2.1.0.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/spark-network-shuffle_2.12-3.5.6.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/hive-serde-2.3.9.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/netty-transport-native-kqueue-4.1.96.Final-osx-x86_64.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/spark-graphx_2.12-3.5.6.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/compress-lzf-1.1.2.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/spark-common-utils_2.12-3.5.6.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/datanucleus-rdbms-4.1.19.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/orc-shims-1.9.6.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/commons-cli-1.5.0.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/hk2-locator-2.6.1.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/lapack-3.0.3.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/scala-library-2.12.18.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/jersey-container-servlet-2.40.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/arrow-memory-netty-12.0.1.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/jersey-container-servlet-core-2.40.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/hk2-utils-2.6.1.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/netty-common-4.1.96.Final.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/jsr305-3.0.0.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/parquet-jackson-1.13.1.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/guava-14.0.1.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/datanucleus-api-jdo-4.2.4.jar\n",
            "spark-3.5.6-bin-hadoop3/jars/commons-dbcp-1.4.jar\n",
            "spark-3.5.6-bin-hadoop3/R/\n",
            "spark-3.5.6-bin-hadoop3/R/lib/\n",
            "spark-3.5.6-bin-hadoop3/R/lib/sparkr.zip\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/doc/\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/doc/sparkr-vignettes.Rmd\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/doc/sparkr-vignettes.html\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/doc/sparkr-vignettes.R\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/doc/index.html\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/R/\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/R/SparkR.rdb\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/R/SparkR.rdx\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/R/SparkR\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/worker/\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/worker/worker.R\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/worker/daemon.R\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/html/\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/html/R.css\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/html/00Index.html\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/NAMESPACE\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/tests/\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/tests/testthat/\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/tests/testthat/test_basic.R\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/profile/\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/profile/general.R\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/profile/shell.R\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/DESCRIPTION\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/help/\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/help/paths.rds\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/help/SparkR.rdb\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/help/SparkR.rdx\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/help/aliases.rds\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/help/AnIndex\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/Meta/\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/Meta/features.rds\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/Meta/package.rds\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/Meta/nsInfo.rds\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/Meta/hsearch.rds\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/Meta/links.rds\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/Meta/Rd.rds\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/Meta/vignette.rds\n",
            "spark-3.5.6-bin-hadoop3/R/lib/SparkR/INDEX\n",
            "spark-3.5.6-bin-hadoop3/NOTICE\n",
            "spark-3.5.6-bin-hadoop3/kubernetes/\n",
            "spark-3.5.6-bin-hadoop3/kubernetes/dockerfiles/\n",
            "spark-3.5.6-bin-hadoop3/kubernetes/dockerfiles/spark/\n",
            "spark-3.5.6-bin-hadoop3/kubernetes/dockerfiles/spark/entrypoint.sh\n",
            "spark-3.5.6-bin-hadoop3/kubernetes/dockerfiles/spark/decom.sh\n",
            "spark-3.5.6-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/\n",
            "spark-3.5.6-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/R/\n",
            "spark-3.5.6-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/R/Dockerfile\n",
            "spark-3.5.6-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/python/\n",
            "spark-3.5.6-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/python/Dockerfile\n",
            "spark-3.5.6-bin-hadoop3/kubernetes/dockerfiles/spark/Dockerfile\n",
            "spark-3.5.6-bin-hadoop3/kubernetes/tests/\n",
            "spark-3.5.6-bin-hadoop3/kubernetes/tests/python_executable_check.py\n",
            "spark-3.5.6-bin-hadoop3/kubernetes/tests/worker_memory_check.py\n",
            "spark-3.5.6-bin-hadoop3/kubernetes/tests/py_container_checks.py\n",
            "spark-3.5.6-bin-hadoop3/kubernetes/tests/pyfiles.py\n",
            "spark-3.5.6-bin-hadoop3/kubernetes/tests/decommissioning.py\n",
            "spark-3.5.6-bin-hadoop3/kubernetes/tests/autoscale.py\n",
            "spark-3.5.6-bin-hadoop3/kubernetes/tests/decommissioning_cleanup.py\n",
            "spark-3.5.6-bin-hadoop3/conf/\n",
            "spark-3.5.6-bin-hadoop3/conf/workers.template\n",
            "spark-3.5.6-bin-hadoop3/conf/spark-env.sh.template\n",
            "spark-3.5.6-bin-hadoop3/conf/fairscheduler.xml.template\n",
            "spark-3.5.6-bin-hadoop3/conf/spark-defaults.conf.template\n",
            "spark-3.5.6-bin-hadoop3/conf/metrics.properties.template\n",
            "spark-3.5.6-bin-hadoop3/conf/log4j2.properties.template\n",
            "spark-3.5.6-bin-hadoop3/bin/\n",
            "spark-3.5.6-bin-hadoop3/bin/run-example.cmd\n",
            "spark-3.5.6-bin-hadoop3/bin/sparkR.cmd\n",
            "spark-3.5.6-bin-hadoop3/bin/sparkR2.cmd\n",
            "spark-3.5.6-bin-hadoop3/bin/sparkR\n",
            "spark-3.5.6-bin-hadoop3/bin/spark-shell.cmd\n",
            "spark-3.5.6-bin-hadoop3/bin/spark-connect-shell\n",
            "spark-3.5.6-bin-hadoop3/bin/spark-sql\n",
            "spark-3.5.6-bin-hadoop3/bin/find-spark-home\n",
            "spark-3.5.6-bin-hadoop3/bin/spark-submit.cmd\n",
            "spark-3.5.6-bin-hadoop3/bin/spark-class2.cmd\n",
            "spark-3.5.6-bin-hadoop3/bin/run-example\n",
            "spark-3.5.6-bin-hadoop3/bin/beeline.cmd\n",
            "spark-3.5.6-bin-hadoop3/bin/load-spark-env.cmd\n",
            "spark-3.5.6-bin-hadoop3/bin/spark-shell2.cmd\n",
            "spark-3.5.6-bin-hadoop3/bin/spark-sql.cmd\n",
            "spark-3.5.6-bin-hadoop3/bin/spark-class\n",
            "spark-3.5.6-bin-hadoop3/bin/spark-sql2.cmd\n",
            "spark-3.5.6-bin-hadoop3/bin/spark-shell\n",
            "spark-3.5.6-bin-hadoop3/bin/spark-class.cmd\n",
            "spark-3.5.6-bin-hadoop3/bin/spark-submit\n",
            "spark-3.5.6-bin-hadoop3/bin/beeline\n",
            "spark-3.5.6-bin-hadoop3/bin/find-spark-home.cmd\n",
            "spark-3.5.6-bin-hadoop3/bin/spark-submit2.cmd\n",
            "spark-3.5.6-bin-hadoop3/bin/pyspark.cmd\n",
            "spark-3.5.6-bin-hadoop3/bin/pyspark2.cmd\n",
            "spark-3.5.6-bin-hadoop3/bin/pyspark\n",
            "spark-3.5.6-bin-hadoop3/bin/docker-image-tool.sh\n",
            "spark-3.5.6-bin-hadoop3/bin/load-spark-env.sh\n",
            "spark-3.5.6-bin-hadoop3/licenses/\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-AnchorJS.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-minlog.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-janino.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-JTransforms.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-jline.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-mustache.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-jquery.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-jsp-api.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-jodd.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-xmlenc.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-scopt.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-zstd-jni.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-sbt-launch-lib.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-spire.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-dagre-d3.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-pyrolite.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-javolution.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-jakarta-annotation-api\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-javax-transaction-transaction-api.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-py4j.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-javassist.html\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-blas.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-arpack.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-istack-commons-runtime.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-dnsjava.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-sorttable.js.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-d3.min.js.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-protobuf.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-jakarta.xml.bind-api.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-machinist.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-JLargeArrays.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-re2j.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-jakarta-ws-rs-api\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-jaxb-runtime.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-kryo.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-zstd.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-paranamer.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-bootstrap.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-leveldbjni.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-f2j.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-vis-timeline.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-modernizr.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-pmml-model.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-datatables.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-json-formatter.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-graphlib-dot.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-reflectasm.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-antlr.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-CC0.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-cloudpickle.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-automaton.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-join.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-respond.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-jakarta.activation-api.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-matchMedia-polyfill.txt\n",
            "spark-3.5.6-bin-hadoop3/licenses/LICENSE-slf4j.txt\n",
            "spark-3.5.6-bin-hadoop3/README.md\n",
            "spark-3.5.6-bin-hadoop3/LICENSE\n",
            "spark-3.5.6-bin-hadoop3/data/\n",
            "spark-3.5.6-bin-hadoop3/data/mllib/\n",
            "spark-3.5.6-bin-hadoop3/data/mllib/streaming_kmeans_data_test.txt\n",
            "spark-3.5.6-bin-hadoop3/data/mllib/kmeans_data.txt\n",
            "spark-3.5.6-bin-hadoop3/data/mllib/sample_libsvm_data.txt\n",
            "spark-3.5.6-bin-hadoop3/data/mllib/sample_kmeans_data.txt\n",
            "spark-3.5.6-bin-hadoop3/data/mllib/sample_multiclass_classification_data.txt\n",
            "spark-3.5.6-bin-hadoop3/data/mllib/pic_data.txt\n",
            "spark-3.5.6-bin-hadoop3/data/mllib/sample_lda_libsvm_data.txt\n",
            "spark-3.5.6-bin-hadoop3/data/mllib/sample_isotonic_regression_libsvm_data.txt\n",
            "spark-3.5.6-bin-hadoop3/data/mllib/als/\n",
            "spark-3.5.6-bin-hadoop3/data/mllib/als/sample_movielens_ratings.txt\n",
            "spark-3.5.6-bin-hadoop3/data/mllib/als/test.data\n",
            "spark-3.5.6-bin-hadoop3/data/mllib/ridge-data/\n",
            "spark-3.5.6-bin-hadoop3/data/mllib/ridge-data/lpsa.data\n",
            "spark-3.5.6-bin-hadoop3/data/mllib/sample_lda_data.txt\n",
            "spark-3.5.6-bin-hadoop3/data/mllib/images/\n",
            "spark-3.5.6-bin-hadoop3/data/mllib/images/license.txt\n",
            "spark-3.5.6-bin-hadoop3/data/mllib/images/origin/\n",
            "spark-3.5.6-bin-hadoop3/data/mllib/images/origin/kittens/\n",
            "spark-3.5.6-bin-hadoop3/data/mllib/images/origin/kittens/DP153539.jpg\n",
            "spark-3.5.6-bin-hadoop3/data/mllib/images/origin/kittens/DP802813.jpg\n",
            "spark-3.5.6-bin-hadoop3/data/mllib/images/origin/kittens/not-image.txt\n",
            "spark-3.5.6-bin-hadoop3/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg\n",
            "spark-3.5.6-bin-hadoop3/data/mllib/images/origin/kittens/54893.jpg\n",
            "spark-3.5.6-bin-hadoop3/data/mllib/images/origin/license.txt\n",
            "spark-3.5.6-bin-hadoop3/data/mllib/images/origin/multi-channel/\n",
            "spark-3.5.6-bin-hadoop3/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png\n",
            "spark-3.5.6-bin-hadoop3/data/mllib/images/origin/multi-channel/BGRA.png\n",
            "spark-3.5.6-bin-hadoop3/data/mllib/images/origin/multi-channel/grayscale.jpg\n",
            "spark-3.5.6-bin-hadoop3/data/mllib/images/origin/multi-channel/chr30.4.184.jpg\n",
            "spark-3.5.6-bin-hadoop3/data/mllib/sample_linear_regression_data.txt\n",
            "spark-3.5.6-bin-hadoop3/data/mllib/gmm_data.txt\n",
            "spark-3.5.6-bin-hadoop3/data/mllib/sample_fpgrowth.txt\n",
            "spark-3.5.6-bin-hadoop3/data/mllib/sample_svm_data.txt\n",
            "spark-3.5.6-bin-hadoop3/data/mllib/sample_movielens_data.txt\n",
            "spark-3.5.6-bin-hadoop3/data/mllib/pagerank_data.txt\n",
            "spark-3.5.6-bin-hadoop3/data/mllib/sample_binary_classification_data.txt\n",
            "spark-3.5.6-bin-hadoop3/data/artifact-tests/\n",
            "spark-3.5.6-bin-hadoop3/data/artifact-tests/crc/\n",
            "spark-3.5.6-bin-hadoop3/data/artifact-tests/crc/README.md\n",
            "spark-3.5.6-bin-hadoop3/data/artifact-tests/crc/junitLargeJar.txt\n",
            "spark-3.5.6-bin-hadoop3/data/artifact-tests/crc/smallJar.txt\n",
            "spark-3.5.6-bin-hadoop3/data/artifact-tests/smallJar.jar\n",
            "spark-3.5.6-bin-hadoop3/data/artifact-tests/junitLargeJar.jar\n",
            "spark-3.5.6-bin-hadoop3/data/streaming/\n",
            "spark-3.5.6-bin-hadoop3/data/streaming/AFINN-111.txt\n",
            "spark-3.5.6-bin-hadoop3/data/graphx/\n",
            "spark-3.5.6-bin-hadoop3/data/graphx/users.txt\n",
            "spark-3.5.6-bin-hadoop3/data/graphx/followers.txt\n",
            "spark-3.5.6-bin-hadoop3/sbin/\n",
            "spark-3.5.6-bin-hadoop3/sbin/start-mesos-shuffle-service.sh\n",
            "spark-3.5.6-bin-hadoop3/sbin/decommission-slave.sh\n",
            "spark-3.5.6-bin-hadoop3/sbin/start-connect-server.sh\n",
            "spark-3.5.6-bin-hadoop3/sbin/stop-slave.sh\n",
            "spark-3.5.6-bin-hadoop3/sbin/spark-daemon.sh\n",
            "spark-3.5.6-bin-hadoop3/sbin/start-slaves.sh\n",
            "spark-3.5.6-bin-hadoop3/sbin/spark-config.sh\n",
            "spark-3.5.6-bin-hadoop3/sbin/stop-all.sh\n",
            "spark-3.5.6-bin-hadoop3/sbin/stop-connect-server.sh\n",
            "spark-3.5.6-bin-hadoop3/sbin/stop-mesos-dispatcher.sh\n",
            "spark-3.5.6-bin-hadoop3/sbin/start-workers.sh\n",
            "spark-3.5.6-bin-hadoop3/sbin/start-history-server.sh\n",
            "spark-3.5.6-bin-hadoop3/sbin/start-all.sh\n",
            "spark-3.5.6-bin-hadoop3/sbin/spark-daemons.sh\n",
            "spark-3.5.6-bin-hadoop3/sbin/stop-workers.sh\n",
            "spark-3.5.6-bin-hadoop3/sbin/start-slave.sh\n",
            "spark-3.5.6-bin-hadoop3/sbin/stop-history-server.sh\n",
            "spark-3.5.6-bin-hadoop3/sbin/decommission-worker.sh\n",
            "spark-3.5.6-bin-hadoop3/sbin/stop-slaves.sh\n",
            "spark-3.5.6-bin-hadoop3/sbin/start-mesos-dispatcher.sh\n",
            "spark-3.5.6-bin-hadoop3/sbin/workers.sh\n",
            "spark-3.5.6-bin-hadoop3/sbin/slaves.sh\n",
            "spark-3.5.6-bin-hadoop3/sbin/stop-worker.sh\n",
            "spark-3.5.6-bin-hadoop3/sbin/stop-master.sh\n",
            "spark-3.5.6-bin-hadoop3/sbin/stop-thriftserver.sh\n",
            "spark-3.5.6-bin-hadoop3/sbin/stop-mesos-shuffle-service.sh\n",
            "spark-3.5.6-bin-hadoop3/sbin/start-master.sh\n",
            "spark-3.5.6-bin-hadoop3/sbin/start-worker.sh\n",
            "spark-3.5.6-bin-hadoop3/sbin/start-thriftserver.sh\n",
            "spark-3.5.6-bin-hadoop3/python/\n",
            "spark-3.5.6-bin-hadoop3/python/setup.cfg\n",
            "spark-3.5.6-bin-hadoop3/python/setup.py\n",
            "spark-3.5.6-bin-hadoop3/python/test_support/\n",
            "spark-3.5.6-bin-hadoop3/python/test_support/test_pytorch_training_file.py\n",
            "spark-3.5.6-bin-hadoop3/python/test_support/sql/\n",
            "spark-3.5.6-bin-hadoop3/python/test_support/sql/orc_partitioned/\n",
            "spark-3.5.6-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/\n",
            "spark-3.5.6-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/c=1/\n",
            "spark-3.5.6-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/c=1/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-3.5.6-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/c=1/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-3.5.6-bin-hadoop3/python/test_support/sql/orc_partitioned/_SUCCESS\n",
            "spark-3.5.6-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/\n",
            "spark-3.5.6-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/c=0/\n",
            "spark-3.5.6-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/c=0/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-3.5.6-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/c=0/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-3.5.6-bin-hadoop3/python/test_support/sql/people1.json\n",
            "spark-3.5.6-bin-hadoop3/python/test_support/sql/text-test.txt\n",
            "spark-3.5.6-bin-hadoop3/python/test_support/sql/people.json\n",
            "spark-3.5.6-bin-hadoop3/python/test_support/sql/people_array.json\n",
            "spark-3.5.6-bin-hadoop3/python/test_support/sql/people_array_utf16le.json\n",
            "spark-3.5.6-bin-hadoop3/python/test_support/sql/streaming/\n",
            "spark-3.5.6-bin-hadoop3/python/test_support/sql/streaming/text-test.txt\n",
            "spark-3.5.6-bin-hadoop3/python/test_support/sql/ages_newlines.csv\n",
            "spark-3.5.6-bin-hadoop3/python/test_support/userlib-0.1.zip\n",
            "spark-3.5.6-bin-hadoop3/python/test_support/userlibrary.py\n",
            "spark-3.5.6-bin-hadoop3/python/test_support/hello/\n",
            "spark-3.5.6-bin-hadoop3/python/test_support/hello/hello.txt\n",
            "spark-3.5.6-bin-hadoop3/python/test_support/hello/sub_hello/\n",
            "spark-3.5.6-bin-hadoop3/python/test_support/hello/sub_hello/sub_hello.txt\n",
            "spark-3.5.6-bin-hadoop3/python/test_support/SimpleHTTPServer.py\n",
            "spark-3.5.6-bin-hadoop3/python/lib/\n",
            "spark-3.5.6-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip\n",
            "spark-3.5.6-bin-hadoop3/python/lib/pyspark.zip\n",
            "spark-3.5.6-bin-hadoop3/python/lib/PY4J_LICENSE.txt\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark.egg-info/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark.egg-info/dependency_links.txt\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark.egg-info/SOURCES.txt\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark.egg-info/requires.txt\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark.egg-info/top_level.txt\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark.egg-info/PKG-INFO\n",
            "spark-3.5.6-bin-hadoop3/python/test_coverage/\n",
            "spark-3.5.6-bin-hadoop3/python/test_coverage/sitecustomize.py\n",
            "spark-3.5.6-bin-hadoop3/python/test_coverage/conf/\n",
            "spark-3.5.6-bin-hadoop3/python/test_coverage/conf/spark-defaults.conf\n",
            "spark-3.5.6-bin-hadoop3/python/test_coverage/coverage_daemon.py\n",
            "spark-3.5.6-bin-hadoop3/python/run-tests.py\n",
            "spark-3.5.6-bin-hadoop3/python/run-tests\n",
            "spark-3.5.6-bin-hadoop3/python/MANIFEST.in\n",
            "spark-3.5.6-bin-hadoop3/python/README.md\n",
            "spark-3.5.6-bin-hadoop3/python/run-tests-with-coverage\n",
            "spark-3.5.6-bin-hadoop3/python/mypy.ini\n",
            "spark-3.5.6-bin-hadoop3/python/.gitignore\n",
            "spark-3.5.6-bin-hadoop3/python/docs/\n",
            "spark-3.5.6-bin-hadoop3/python/docs/Makefile\n",
            "spark-3.5.6-bin-hadoop3/python/docs/make.bat\n",
            "spark-3.5.6-bin-hadoop3/python/docs/make2.bat\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.streaming.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.mllib.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/index.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.resource.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.errors.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.pandas/\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.pandas/resampling.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.pandas/indexing.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.pandas/index.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.pandas/window.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.pandas/io.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.pandas/extensions.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.pandas/general_functions.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.pandas/series.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.pandas/ml.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.pandas/frame.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.pandas/groupby.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.ml.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.ss/\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.ss/query_management.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.ss/index.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.ss/io.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.ss/core_classes.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.sql/\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.sql/data_types.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.sql/udtf.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.sql/udf.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.sql/column.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.sql/index.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.sql/dataframe.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.sql/window.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.sql/io.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.sql/avro.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.sql/row.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.sql/configuration.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.sql/functions.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.sql/observation.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.sql/spark_session.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.sql/protobuf.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.sql/grouping.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.sql/core_classes.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.sql/catalog.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/reference/pyspark.testing.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/_static/\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/_static/css/\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/_static/css/pyspark.css\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/index.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/getting_started/\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/getting_started/index.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/getting_started/quickstart_ps.ipynb\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/getting_started/quickstart_df.ipynb\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/getting_started/quickstart_connect.ipynb\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/getting_started/install.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/getting_started/testing_pyspark.ipynb\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/conf.py\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/_templates/\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/_templates/autosummary/\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/_templates/autosummary/class_with_docs.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/_templates/autosummary/class.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/_templates/version-switcher.html\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/user_guide/\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/user_guide/arrow_pandas.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/user_guide/index.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/user_guide/sql/\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/user_guide/sql/arrow_pandas.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/user_guide/sql/index.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/user_guide/sql/python_udtf.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/index.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/best_practices.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/typehints.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/options.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/from_to_dbms.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/transform_apply.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/types.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/faq.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/pandas_pyspark.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/user_guide/python_packaging.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/migration_guide/\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/migration_guide/index.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/migration_guide/pyspark_upgrade.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/migration_guide/koalas_to_pyspark.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/development/\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/development/testing.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/development/index.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/development/debugging.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/development/setting_ide.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/development/contributing.rst\n",
            "spark-3.5.6-bin-hadoop3/python/docs/source/development/errors.rst\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/mllib/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/mllib/clustering.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/mllib/feature.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/mllib/regression.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/mllib/random.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/mllib/recommendation.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/mllib/evaluation.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/mllib/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/mllib/util.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/mllib/tests/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/mllib/tests/test_stat.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/mllib/tests/test_algorithms.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/mllib/tests/test_streaming_algorithms.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/mllib/tests/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/mllib/tests/test_feature.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/mllib/tests/test_linalg.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/mllib/tests/test_util.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/mllib/linalg/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/mllib/linalg/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/mllib/linalg/distributed.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/mllib/classification.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/mllib/_typing.pyi\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/mllib/tree.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/mllib/common.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/mllib/stat/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/mllib/stat/test.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/mllib/stat/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/mllib/stat/KernelDensity.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/mllib/stat/_statistics.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/mllib/stat/distribution.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/mllib/fpm.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/serializers.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/join.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/testing/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/testing/connectutils.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/testing/mllibutils.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/testing/streamingutils.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/testing/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/testing/mlutils.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/testing/objects.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/testing/sqlutils.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/testing/utils.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/testing/pandasutils.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/errors/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/errors/exceptions/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/errors/exceptions/base.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/errors/exceptions/connect.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/errors/exceptions/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/errors/exceptions/captured.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/errors/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/errors/tests/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/errors/tests/test_errors.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/errors/tests/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/errors/error_classes.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/errors/utils.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/indexing.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/extensions.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/mlflow.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/_typing.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/frame.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/base.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/categorical.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/config.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/supported_api_gen.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/plot/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/plot/matplotlib.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/plot/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/plot/core.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/plot/plotly.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/sql_formatter.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/resample.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/test_numpy_compat.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/groupby/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_apply_func.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_stat.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_missing_data.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/groupby/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_groupby.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_index.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_aggregate.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_split_apply.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_head_tail.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_cumulative.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_describe.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/test_namespace.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/test_series_string.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/test_indexing.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/test_reshape.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/test_internal.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/test_series_datetime.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby_expanding.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/test_indexops_spark.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/test_stats.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/test_typedef.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/io/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/io/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/io/test_io.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/test_scalars.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby_rolling.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/test_series_conversion.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/test_categorical.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/test_window.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/test_cov_corrwith.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/test_setitem_series.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/test_basic_slow.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/test_index.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/test_align.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/test_dot_series.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/test_series.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/test_setitem_frame.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/test_dot_frame.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/series/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/series/test_stat.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/series/test_missing_data.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/series/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/series/test_index.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/series/test_conversion.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/series/test_arg_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/series/test_sort.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/series/test_series.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/series/test_as_type.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/series/test_compute.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/series/test_all_any.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/series/test_as_of.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/series/test_cumulative.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/test_expanding.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/plot/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/plot/test_frame_plot.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/plot/test_frame_plot_matplotlib.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/plot/test_series_plot_matplotlib.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/plot/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/plot/test_frame_plot_plotly.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/plot/test_series_plot.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/plot/test_series_plot_plotly.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/test_config.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/test_csv.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/test_rolling.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_aggregate.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_missing_data.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_apply_func.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_stat.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_cumulative.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_index.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_head_tail.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_groupby.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_split_apply.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_describe.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_rolling.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_extension.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_window.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_config.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_expanding.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/io/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/io/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/io/test_parity_io.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_utils.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_ewm.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_scalars.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_ops_on_diff_frames.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_dataframe_spark_io.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_indexing.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/test_parity_setitem_series.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/test_parity_series.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/test_parity_basic_slow.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/test_parity_dot_series.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/test_parity_cov_corrwith.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/test_parity_index.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/test_parity_setitem_frame.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/test_parity_align.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/test_parity_dot_frame.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_generic_functions.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/series/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_series.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/series/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_missing_data.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_as_of.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_stat.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_compute.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_conversion.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_cumulative.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_as_type.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_sort.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_index.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_arg_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_all_any.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/plot/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/plot/test_parity_frame_plot_matplotlib.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/plot/test_parity_frame_plot.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/plot/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/plot/test_parity_series_plot_plotly.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/plot/test_parity_series_plot.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/plot/test_parity_series_plot_matplotlib.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/plot/test_parity_frame_plot_plotly.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_ops_on_diff_frames_groupby_expanding.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_stats.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_reshape.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_internal.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_typedef.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_series_conversion.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_dataframe_conversion.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_ops_on_diff_frames_groupby.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_series_datetime.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_combine.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_corrwith.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_any_all.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_binary_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_melt.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_missing_data.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_cov.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_eval.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_apply_func.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_compute.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_cumulative.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_pivot.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_describe.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_spark_functions.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_resample.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_frame_spark.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_series_string.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_repr.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_csv.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_categorical.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/test_parity_base.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/test_parity_datetime.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/test_parity_reindex.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/test_parity_indexing.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/test_parity_reset_index.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/test_parity_timedelta.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/test_parity_rename.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/test_parity_category.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/test_parity_align.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_default_index.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_ops_on_diff_frames_groupby_rolling.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_indexops_spark.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_namespace.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/test_parity_reindexing.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/test_parity_truncate.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/test_parity_attrs.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/test_parity_constructor.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/test_parity_conversion.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/test_parity_take.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/test_parity_reshaping.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/test_parity_spark.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/test_parity_time_series.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_numpy_compat.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_binary_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_base.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_null_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_complex_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_datetime_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_udt_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_num_arithmetic.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_date_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_categorical_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_num_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/testing_utils.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_string_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_timedelta_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_num_reverse.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_boolean_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_sql.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/computation/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/computation/test_apply_func.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/computation/test_missing_data.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/computation/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/computation/test_melt.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/computation/test_combine.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/computation/test_binary_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/computation/test_corrwith.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/computation/test_compute.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/computation/test_eval.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/computation/test_cov.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/computation/test_pivot.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/computation/test_any_all.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/computation/test_cumulative.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/computation/test_describe.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/test_spark_functions.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/test_resample.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/test_repr.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/test_ewm.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/test_default_index.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/test_sql.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/test_generic_functions.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/test_frame_spark.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/test_extension.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/indexes/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_base.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_indexing.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/indexes/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_align.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_rename.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_datetime.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_category.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_reindex.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_timedelta.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_reset_index.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/test_dataframe_spark_io.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/test_utils.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/frame/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/frame/test_take.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/frame/test_time_series.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/frame/test_attrs.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/frame/test_reindexing.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/frame/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/frame/test_truncate.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/frame/test_spark.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/frame/test_conversion.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/frame/test_reshaping.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/frame/test_constructor.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_base.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_datetime_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_num_arithmetic.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_complex_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_num_reverse.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_categorical_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_null_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_binary_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_string_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/testing_utils.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_num_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_timedelta_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_udt_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_date_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_boolean_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/tests/test_dataframe_conversion.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/datetimes.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/groupby.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/spark/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/spark/functions.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/spark/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/spark/accessors.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/spark/utils.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/exceptions.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/strings.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/sql_processor.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/namespace.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/generic.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/internal.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/missing/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/missing/frame.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/missing/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/missing/resample.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/missing/groupby.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/missing/indexes.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/missing/scalars.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/missing/window.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/missing/common.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/missing/series.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/missing/general_functions.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/typedef/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/typedef/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/typedef/typehints.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/usage_logging/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/usage_logging/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/usage_logging/usage_logger.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/numpy_compat.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/accessors.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/utils.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/indexes/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/indexes/multi.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/indexes/timedelta.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/indexes/base.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/indexes/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/indexes/datetimes.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/indexes/numeric.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/indexes/category.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/window.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/series.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/correlation.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/data_type_ops/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/data_type_ops/null_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/data_type_ops/boolean_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/data_type_ops/num_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/data_type_ops/base.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/data_type_ops/datetime_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/data_type_ops/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/data_type_ops/binary_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/data_type_ops/complex_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/data_type_ops/categorical_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/data_type_ops/udt_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/data_type_ops/string_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/data_type_ops/timedelta_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/pandas/data_type_ops/date_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/worker_util.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/context.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/version.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/rdd.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/statcounter.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/util.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/tests/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/tests/test_appsubmit.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/tests/test_broadcast.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/tests/test_worker.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/tests/test_pin_thread.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/tests/test_install_spark.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/tests/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/tests/test_taskcontext.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/tests/test_rddbarrier.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/tests/test_statcounter.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/tests/test_memory_profiler.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/tests/test_shuffle.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/tests/test_readwrite.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/tests/test_context.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/tests/test_conf.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/tests/test_serializers.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/tests/test_profiler.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/tests/test_daemon.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/tests/test_join.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/tests/test_stage_sched.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/tests/typing/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/tests/typing/test_core.yml\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/tests/typing/test_context.yml\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/tests/typing/test_resultiterable.yml\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/tests/typing/test_rdd.yml\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/tests/test_rddsampler.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/tests/test_rdd.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/tests/test_util.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/functions.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/clustering.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/torch/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/torch/log_communication.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/torch/distributor.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/torch/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/torch/tests/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/torch/tests/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/torch/tests/test_data_loader.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/torch/tests/test_log_communication.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/torch/tests/test_distributor.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/torch/data.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/torch/torch_run_process_wrapper.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/model_cache.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/feature.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/wrapper.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/regression.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/recommendation.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/base.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/evaluation.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/param/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/param/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/param/shared.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/param/_shared_params_code_gen.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/util.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/stat.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/test_base.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/test_image.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/test_stat.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/test_model_cache.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/tuning/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/tuning/test_tvs_io_pipeline.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/tuning/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/tuning/test_cv_io_pipeline.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/tuning/test_tuning.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/tuning/test_tvs_io_basic.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/tuning/test_tvs_io_nested.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/tuning/test_cv_io_basic.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/tuning/test_cv_io_nested.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/test_algorithms.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/test_training_summary.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/test_feature.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/connect/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/connect/test_connect_feature.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/connect/test_connect_evaluation.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/connect/test_connect_summarizer.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/connect/test_legacy_mode_tuning.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/connect/test_legacy_mode_pipeline.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/connect/test_legacy_mode_classification.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/connect/test_connect_function.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/connect/test_legacy_mode_feature.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/connect/test_legacy_mode_summarizer.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/connect/test_legacy_mode_evaluation.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/connect/test_connect_classification.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/connect/test_parity_torch_data_loader.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/connect/test_connect_pipeline.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/connect/test_connect_tuning.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/connect/test_parity_torch_distributor.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/test_functions.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/test_linalg.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/test_dl_util.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/test_param.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/test_wrapper.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/test_persistence.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/typing/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/typing/test_classification.yml\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/typing/test_evaluation.yml\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/typing/test_feature.yml\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/typing/test_readable.yml\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/typing/test_regression.yml\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/typing/test_param.yml\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/typing/test_clustering.yaml\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/test_evaluation.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/test_util.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tests/test_pipeline.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/connect/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/connect/functions.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/connect/feature.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/connect/base.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/connect/evaluation.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/connect/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/connect/util.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/connect/io_utils.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/connect/summarizer.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/connect/tuning.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/connect/classification.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/connect/pipeline.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/deepspeed/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/deepspeed/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/deepspeed/tests/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/deepspeed/tests/test_deepspeed_distributor.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/deepspeed/deepspeed_distributor.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/linalg/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/linalg/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/image.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tuning.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/classification.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/pipeline.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/_typing.pyi\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/tree.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/common.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/fpm.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/ml/dl_util.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/storagelevel.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/conf.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/instrumentation_utils.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/profiler.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/find_spark_home.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/functions.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/session.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/pandas/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/pandas/group_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/pandas/serializers.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/pandas/functions.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/pandas/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/pandas/functions.pyi\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/pandas/types.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/pandas/map_ops.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/pandas/typehints.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/pandas/_typing/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/pandas/_typing/__init__.pyi\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/series.pyi\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/frame.pyi\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/__init__.pyi\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/pandas/utils.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/pandas/conversion.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/context.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/column.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/sql_formatter.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/test_pandas_sqlmetrics.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/test_errors.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/test_readwriter.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/test_arrow.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/pandas/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf_grouped_agg.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf_scalar.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_grouped_map.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf_window.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/pandas/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_cogrouped_map.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf_typehints.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_map.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_grouped_map_with_state.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf_typehints_with_future_annotations.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/test_session.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/test_udtf.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/test_group.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/test_udf_profiler.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/test_serde.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_udf_scalar.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_conf.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_dataframe.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/test_session.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_column.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_catalog.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_types.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/client/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/client/test_client.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/client/test_artifact.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/client/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_cogrouped_map.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_datasources.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_udf.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/test_connect_function.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_udf_grouped_agg.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_udtf.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_serde.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/test_connect_basic.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/test_connect_plan.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_arrow_python_udf.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_grouped_map_with_state.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_errors.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_readwriter.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_map.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/test_connect_column.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_udf_window.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_arrow_map.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_grouped_map.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_arrow.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_functions.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_udf.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_group.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/test_utils.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/streaming/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/streaming/test_parity_listener.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/streaming/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/streaming/test_parity_foreach.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/streaming/test_parity_streaming.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/connect/streaming/test_parity_foreach_batch.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/test_functions.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/test_arrow_map.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/test_context.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/test_types.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/test_conf.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/test_catalog.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/test_udf.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/test_dataframe.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/typing/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/typing/test_dataframe.yml\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/typing/test_readwriter.yml\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/typing/test_functions.yml\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/typing/test_session.yml\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/typing/test_column.yml\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/typing/test_udf.yml\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/test_datasources.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/test_arrow_python_udf.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/test_column.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/test_utils.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/streaming/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/streaming/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/streaming/test_streaming_foreach.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/streaming/test_streaming_foreach_batch.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/streaming/test_streaming.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/tests/streaming/test_streaming_listener.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/types.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/conf.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/functions.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/_typing.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/session.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/expressions.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/column.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/client/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/client/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/client/reattach.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/client/core.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/client/artifact.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/types.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/conf.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/udf.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/avro/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/avro/functions.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/avro/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/catalog.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/plan.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/readwriter.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/udtf.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/utils.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/group.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/window.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/dataframe.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/streaming/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/streaming/worker/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/streaming/worker/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/streaming/worker/foreach_batch_worker.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/streaming/worker/listener_worker.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/streaming/query.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/streaming/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/streaming/readwriter.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/conversion.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/protobuf/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/protobuf/functions.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/protobuf/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/proto/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/proto/catalog_pb2.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/proto/catalog_pb2.pyi\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/proto/example_plugins_pb2.pyi\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/proto/common_pb2.pyi\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/proto/common_pb2.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/proto/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/proto/relations_pb2.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/proto/types_pb2.pyi\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/proto/base_pb2.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/proto/relations_pb2.pyi\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/proto/commands_pb2.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/proto/types_pb2.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/proto/example_plugins_pb2.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/proto/expressions_pb2.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/proto/expressions_pb2.pyi\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/proto/commands_pb2.pyi\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/proto/base_pb2_grpc.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/connect/proto/base_pb2.pyi\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/udf.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/observation.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/avro/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/avro/functions.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/avro/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/catalog.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/readwriter.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/udtf.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/_typing.pyi\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/utils.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/group.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/window.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/dataframe.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/streaming/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/streaming/query.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/streaming/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/streaming/listener.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/streaming/state.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/streaming/readwriter.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/protobuf/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/protobuf/functions.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/sql/protobuf/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/__pycache__/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/__pycache__/install.cpython-38.pyc\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/resultiterable.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/accumulators.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/taskcontext.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/py.typed\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/install.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/broadcast.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/daemon.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/worker.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/rddsampler.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/shuffle.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/traceback_utils.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/shell.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/files.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/resource/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/resource/requests.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/resource/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/resource/tests/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/resource/tests/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/resource/tests/test_resources.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/resource/information.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/resource/profile.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/_globals.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/java_gateway.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/_typing.pyi\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/cloudpickle/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/cloudpickle/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/cloudpickle/cloudpickle.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/cloudpickle/cloudpickle_fast.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/cloudpickle/compat.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/streaming/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/streaming/context.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/streaming/kinesis.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/streaming/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/streaming/util.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/streaming/tests/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/streaming/tests/test_listener.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/streaming/tests/__init__.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/streaming/tests/test_dstream.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/streaming/tests/test_kinesis.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/streaming/tests/test_context.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/streaming/listener.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/streaming/dstream.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/status.py\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/python/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/python/pyspark/\n",
            "spark-3.5.6-bin-hadoop3/python/pyspark/python/pyspark/shell.py\n",
            "spark-3.5.6-bin-hadoop3/python/dist/\n",
            "spark-3.5.6-bin-hadoop3/python/.coveragerc\n"
          ]
        }
      ],
      "source": [
        "# Descompactando os arquivos do hadoop na pasta $SPARK_INSTALL_DIR\n",
        "!tar -xvzf $SPARK_INSTALL_DIR/spark-3.5.6-bin-hadoop3.tgz -C $SPARK_INSTALL_DIR\n",
        "!mv $SPARK_INSTALL_DIR/spark-3.5.6-bin-hadoop3 $SPARK_INSTALL_DIR/spark\n",
        "!rm $SPARK_INSTALL_DIR/spark-3.5.6-bin-hadoop3.tgz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95FLFMII72TW"
      },
      "source": [
        "**Ativando o servidor Spark**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxyoWDKH75gV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b18c6214-d162-4a0f-f998-c8d8512fdb97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "org.apache.spark.deploy.master.Master running as process 11664.  Stop it first.\n"
          ]
        }
      ],
      "source": [
        "# Iniciando os processos NameNode e DataNode, daemons do HDFS\n",
        "!$SPARK_HOME/sbin/start-master.sh --host localhost --port 7077"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KWJJkWuCQZU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f9437a6-75af-4717-c756-b64364ce6db6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "org.apache.spark.deploy.worker.Worker running as process 11736.  Stop it first.\n"
          ]
        }
      ],
      "source": [
        "# Iniciando os processos relativos ao gerenciador de recursos YARN\n",
        "!$SPARK_HOME/sbin/start-worker.sh spark://localhost:7077"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixNunaJVqFP9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59f087a4-d92b-4f34-896b-05b5a0a24a7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "#!$SPARK_HOME/bin/pyspark --master spark://localhost:7077"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2A-iRLR-Y3E"
      },
      "source": [
        "# 3. Instalando o Kafka"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5NZNk07-XHK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3a3504f-2766-4b44-b196-3b45d6be424e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kafka-python\n",
            "  Downloading kafka_python-2.2.15-py2.py3-none-any.whl.metadata (10.0 kB)\n",
            "Downloading kafka_python-2.2.15-py2.py3-none-any.whl (309 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/309.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.8/309.8 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: kafka-python\n",
            "Successfully installed kafka-python-2.2.15\n"
          ]
        }
      ],
      "source": [
        "# Instalando o kafka python\n",
        "!pip install kafka-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsJ5Z_A_-ogj"
      },
      "outputs": [],
      "source": [
        "# Fazendo os imports de Producer e Consumer do Kafka\n",
        "from kafka import KafkaProducer\n",
        "from kafka import KafkaConsumer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ay7_cNTE-qEw"
      },
      "outputs": [],
      "source": [
        "# Fazendo download do binário do kafka\n",
        "!curl -sSOL https://dlcdn.apache.org/kafka/3.8.0/kafka_2.13-3.8.0.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_b3iL8B-z3R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1056630-39bf-46ca-89d9-7786a41619fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kafka_2.13-3.8.0/\n",
            "kafka_2.13-3.8.0/LICENSE\n",
            "kafka_2.13-3.8.0/NOTICE\n",
            "kafka_2.13-3.8.0/bin/\n",
            "kafka_2.13-3.8.0/bin/connect-distributed.sh\n",
            "kafka_2.13-3.8.0/bin/connect-mirror-maker.sh\n",
            "kafka_2.13-3.8.0/bin/connect-plugin-path.sh\n",
            "kafka_2.13-3.8.0/bin/connect-standalone.sh\n",
            "kafka_2.13-3.8.0/bin/kafka-acls.sh\n",
            "kafka_2.13-3.8.0/bin/kafka-broker-api-versions.sh\n",
            "kafka_2.13-3.8.0/bin/kafka-client-metrics.sh\n",
            "kafka_2.13-3.8.0/bin/kafka-cluster.sh\n",
            "kafka_2.13-3.8.0/bin/kafka-configs.sh\n",
            "kafka_2.13-3.8.0/bin/kafka-console-consumer.sh\n",
            "kafka_2.13-3.8.0/bin/kafka-console-producer.sh\n",
            "kafka_2.13-3.8.0/bin/kafka-consumer-groups.sh\n",
            "kafka_2.13-3.8.0/bin/kafka-consumer-perf-test.sh\n",
            "kafka_2.13-3.8.0/bin/kafka-delegation-tokens.sh\n",
            "kafka_2.13-3.8.0/bin/kafka-delete-records.sh\n",
            "kafka_2.13-3.8.0/bin/kafka-dump-log.sh\n",
            "kafka_2.13-3.8.0/bin/kafka-e2e-latency.sh\n",
            "kafka_2.13-3.8.0/bin/kafka-features.sh\n",
            "kafka_2.13-3.8.0/bin/kafka-get-offsets.sh\n",
            "kafka_2.13-3.8.0/bin/kafka-jmx.sh\n",
            "kafka_2.13-3.8.0/bin/kafka-leader-election.sh\n",
            "kafka_2.13-3.8.0/bin/kafka-log-dirs.sh\n",
            "kafka_2.13-3.8.0/bin/kafka-metadata-quorum.sh\n",
            "kafka_2.13-3.8.0/bin/kafka-metadata-shell.sh\n",
            "kafka_2.13-3.8.0/bin/kafka-mirror-maker.sh\n",
            "kafka_2.13-3.8.0/bin/kafka-producer-perf-test.sh\n",
            "kafka_2.13-3.8.0/bin/kafka-reassign-partitions.sh\n",
            "kafka_2.13-3.8.0/bin/kafka-replica-verification.sh\n",
            "kafka_2.13-3.8.0/bin/kafka-run-class.sh\n",
            "kafka_2.13-3.8.0/bin/kafka-server-start.sh\n",
            "kafka_2.13-3.8.0/bin/kafka-server-stop.sh\n",
            "kafka_2.13-3.8.0/bin/kafka-storage.sh\n",
            "kafka_2.13-3.8.0/bin/kafka-streams-application-reset.sh\n",
            "kafka_2.13-3.8.0/bin/kafka-topics.sh\n",
            "kafka_2.13-3.8.0/bin/kafka-transactions.sh\n",
            "kafka_2.13-3.8.0/bin/kafka-verifiable-consumer.sh\n",
            "kafka_2.13-3.8.0/bin/kafka-verifiable-producer.sh\n",
            "kafka_2.13-3.8.0/bin/trogdor.sh\n",
            "kafka_2.13-3.8.0/bin/windows/\n",
            "kafka_2.13-3.8.0/bin/windows/connect-distributed.bat\n",
            "kafka_2.13-3.8.0/bin/windows/connect-plugin-path.bat\n",
            "kafka_2.13-3.8.0/bin/windows/connect-standalone.bat\n",
            "kafka_2.13-3.8.0/bin/windows/kafka-acls.bat\n",
            "kafka_2.13-3.8.0/bin/windows/kafka-broker-api-versions.bat\n",
            "kafka_2.13-3.8.0/bin/windows/kafka-client-metrics.bat\n",
            "kafka_2.13-3.8.0/bin/windows/kafka-cluster.bat\n",
            "kafka_2.13-3.8.0/bin/windows/kafka-configs.bat\n",
            "kafka_2.13-3.8.0/bin/windows/kafka-console-consumer.bat\n",
            "kafka_2.13-3.8.0/bin/windows/kafka-console-producer.bat\n",
            "kafka_2.13-3.8.0/bin/windows/kafka-consumer-groups.bat\n",
            "kafka_2.13-3.8.0/bin/windows/kafka-consumer-perf-test.bat\n",
            "kafka_2.13-3.8.0/bin/windows/kafka-delegation-tokens.bat\n",
            "kafka_2.13-3.8.0/bin/windows/kafka-delete-records.bat\n",
            "kafka_2.13-3.8.0/bin/windows/kafka-dump-log.bat\n",
            "kafka_2.13-3.8.0/bin/windows/kafka-e2e-latency.bat\n",
            "kafka_2.13-3.8.0/bin/windows/kafka-features.bat\n",
            "kafka_2.13-3.8.0/bin/windows/kafka-get-offsets.bat\n",
            "kafka_2.13-3.8.0/bin/windows/kafka-jmx.bat\n",
            "kafka_2.13-3.8.0/bin/windows/kafka-leader-election.bat\n",
            "kafka_2.13-3.8.0/bin/windows/kafka-log-dirs.bat\n",
            "kafka_2.13-3.8.0/bin/windows/kafka-metadata-quorum.bat\n",
            "kafka_2.13-3.8.0/bin/windows/kafka-mirror-maker.bat\n",
            "kafka_2.13-3.8.0/bin/windows/kafka-producer-perf-test.bat\n",
            "kafka_2.13-3.8.0/bin/windows/kafka-reassign-partitions.bat\n",
            "kafka_2.13-3.8.0/bin/windows/kafka-replica-verification.bat\n",
            "kafka_2.13-3.8.0/bin/windows/kafka-run-class.bat\n",
            "kafka_2.13-3.8.0/bin/windows/kafka-server-start.bat\n",
            "kafka_2.13-3.8.0/bin/windows/kafka-server-stop.bat\n",
            "kafka_2.13-3.8.0/bin/windows/kafka-storage.bat\n",
            "kafka_2.13-3.8.0/bin/windows/kafka-streams-application-reset.bat\n",
            "kafka_2.13-3.8.0/bin/windows/kafka-topics.bat\n",
            "kafka_2.13-3.8.0/bin/windows/kafka-transactions.bat\n",
            "kafka_2.13-3.8.0/bin/windows/zookeeper-server-start.bat\n",
            "kafka_2.13-3.8.0/bin/windows/zookeeper-server-stop.bat\n",
            "kafka_2.13-3.8.0/bin/windows/zookeeper-shell.bat\n",
            "kafka_2.13-3.8.0/bin/zookeeper-security-migration.sh\n",
            "kafka_2.13-3.8.0/bin/zookeeper-server-start.sh\n",
            "kafka_2.13-3.8.0/bin/zookeeper-server-stop.sh\n",
            "kafka_2.13-3.8.0/bin/zookeeper-shell.sh\n",
            "kafka_2.13-3.8.0/config/\n",
            "kafka_2.13-3.8.0/config/connect-console-sink.properties\n",
            "kafka_2.13-3.8.0/config/connect-console-source.properties\n",
            "kafka_2.13-3.8.0/config/connect-distributed.properties\n",
            "kafka_2.13-3.8.0/config/connect-file-sink.properties\n",
            "kafka_2.13-3.8.0/config/connect-file-source.properties\n",
            "kafka_2.13-3.8.0/config/connect-log4j.properties\n",
            "kafka_2.13-3.8.0/config/connect-mirror-maker.properties\n",
            "kafka_2.13-3.8.0/config/connect-standalone.properties\n",
            "kafka_2.13-3.8.0/config/consumer.properties\n",
            "kafka_2.13-3.8.0/config/kraft/\n",
            "kafka_2.13-3.8.0/config/kraft/broker.properties\n",
            "kafka_2.13-3.8.0/config/kraft/controller.properties\n",
            "kafka_2.13-3.8.0/config/kraft/server.properties\n",
            "kafka_2.13-3.8.0/config/log4j.properties\n",
            "kafka_2.13-3.8.0/config/producer.properties\n",
            "kafka_2.13-3.8.0/config/server.properties\n",
            "kafka_2.13-3.8.0/config/tools-log4j.properties\n",
            "kafka_2.13-3.8.0/config/trogdor.conf\n",
            "kafka_2.13-3.8.0/config/zookeeper.properties\n",
            "kafka_2.13-3.8.0/licenses/\n",
            "kafka_2.13-3.8.0/licenses/CDDL+GPL-1.1\n",
            "kafka_2.13-3.8.0/licenses/DWTFYWTPL\n",
            "kafka_2.13-3.8.0/licenses/argparse-MIT\n",
            "kafka_2.13-3.8.0/licenses/checker-qual-MIT\n",
            "kafka_2.13-3.8.0/licenses/eclipse-distribution-license-1.0\n",
            "kafka_2.13-3.8.0/licenses/eclipse-public-license-2.0\n",
            "kafka_2.13-3.8.0/licenses/jline-BSD-3-clause\n",
            "kafka_2.13-3.8.0/licenses/jopt-simple-MIT\n",
            "kafka_2.13-3.8.0/licenses/jsr305-BSD-3-clause\n",
            "kafka_2.13-3.8.0/licenses/paranamer-BSD-3-clause\n",
            "kafka_2.13-3.8.0/licenses/pcollections-MIT\n",
            "kafka_2.13-3.8.0/licenses/protobuf-java-BSD-3-clause\n",
            "kafka_2.13-3.8.0/licenses/slf4j-MIT\n",
            "kafka_2.13-3.8.0/licenses/zstd-jni-BSD-2-clause\n",
            "kafka_2.13-3.8.0/libs/\n",
            "kafka_2.13-3.8.0/libs/kafka-server-3.8.0.jar\n",
            "kafka_2.13-3.8.0/libs/kafka-group-coordinator-3.8.0.jar\n",
            "kafka_2.13-3.8.0/libs/kafka-metadata-3.8.0.jar\n",
            "kafka_2.13-3.8.0/libs/kafka-storage-3.8.0.jar\n",
            "kafka_2.13-3.8.0/libs/kafka-storage-api-3.8.0.jar\n",
            "kafka_2.13-3.8.0/libs/kafka-raft-3.8.0.jar\n",
            "kafka_2.13-3.8.0/libs/kafka-server-common-3.8.0.jar\n",
            "kafka_2.13-3.8.0/libs/kafka-group-coordinator-api-3.8.0.jar\n",
            "kafka_2.13-3.8.0/libs/kafka-tools-api-3.8.0.jar\n",
            "kafka_2.13-3.8.0/libs/kafka-clients-3.8.0.jar\n",
            "kafka_2.13-3.8.0/libs/jackson-dataformat-csv-2.16.2.jar\n",
            "kafka_2.13-3.8.0/libs/jackson-datatype-jdk8-2.16.2.jar\n",
            "kafka_2.13-3.8.0/libs/jackson-databind-2.16.2.jar\n",
            "kafka_2.13-3.8.0/libs/jackson-annotations-2.16.2.jar\n",
            "kafka_2.13-3.8.0/libs/jackson-core-2.16.2.jar\n",
            "kafka_2.13-3.8.0/libs/jackson-module-scala_2.13-2.16.2.jar\n",
            "kafka_2.13-3.8.0/libs/scala-collection-compat_2.13-2.10.0.jar\n",
            "kafka_2.13-3.8.0/libs/scala-java8-compat_2.13-1.0.2.jar\n",
            "kafka_2.13-3.8.0/libs/scala-logging_2.13-3.9.4.jar\n",
            "kafka_2.13-3.8.0/libs/scala-reflect-2.13.14.jar\n",
            "kafka_2.13-3.8.0/libs/scala-library-2.13.14.jar\n",
            "kafka_2.13-3.8.0/libs/kafka-transaction-coordinator-3.8.0.jar\n",
            "kafka_2.13-3.8.0/libs/argparse4j-0.7.0.jar\n",
            "kafka_2.13-3.8.0/libs/commons-validator-1.7.jar\n",
            "kafka_2.13-3.8.0/libs/jopt-simple-5.0.4.jar\n",
            "kafka_2.13-3.8.0/libs/jose4j-0.9.4.jar\n",
            "kafka_2.13-3.8.0/libs/metrics-core-2.2.0.jar\n",
            "kafka_2.13-3.8.0/libs/metrics-core-4.1.12.1.jar\n",
            "kafka_2.13-3.8.0/libs/zookeeper-3.8.4.jar\n",
            "kafka_2.13-3.8.0/libs/slf4j-api-1.7.36.jar\n",
            "kafka_2.13-3.8.0/libs/commons-cli-1.4.jar\n",
            "kafka_2.13-3.8.0/libs/commons-beanutils-1.9.4.jar\n",
            "kafka_2.13-3.8.0/libs/commons-logging-1.2.jar\n",
            "kafka_2.13-3.8.0/libs/commons-collections-3.2.2.jar\n",
            "kafka_2.13-3.8.0/libs/commons-digester-2.1.jar\n",
            "kafka_2.13-3.8.0/libs/paranamer-2.8.jar\n",
            "kafka_2.13-3.8.0/libs/zookeeper-jute-3.8.4.jar\n",
            "kafka_2.13-3.8.0/libs/audience-annotations-0.12.0.jar\n",
            "kafka_2.13-3.8.0/libs/netty-handler-4.1.110.Final.jar\n",
            "kafka_2.13-3.8.0/libs/netty-transport-native-epoll-4.1.110.Final.jar\n",
            "kafka_2.13-3.8.0/libs/netty-transport-classes-epoll-4.1.110.Final.jar\n",
            "kafka_2.13-3.8.0/libs/netty-transport-native-unix-common-4.1.110.Final.jar\n",
            "kafka_2.13-3.8.0/libs/netty-codec-4.1.110.Final.jar\n",
            "kafka_2.13-3.8.0/libs/netty-transport-4.1.110.Final.jar\n",
            "kafka_2.13-3.8.0/libs/netty-resolver-4.1.110.Final.jar\n",
            "kafka_2.13-3.8.0/libs/netty-buffer-4.1.110.Final.jar\n",
            "kafka_2.13-3.8.0/libs/netty-common-4.1.110.Final.jar\n",
            "kafka_2.13-3.8.0/libs/commons-io-2.11.0.jar\n",
            "kafka_2.13-3.8.0/libs/zstd-jni-1.5.6-3.jar\n",
            "kafka_2.13-3.8.0/libs/lz4-java-1.8.0.jar\n",
            "kafka_2.13-3.8.0/libs/snappy-java-1.1.10.5.jar\n",
            "kafka_2.13-3.8.0/libs/opentelemetry-proto-1.0.0-alpha.jar\n",
            "kafka_2.13-3.8.0/libs/pcollections-4.0.1.jar\n",
            "kafka_2.13-3.8.0/libs/caffeine-2.9.3.jar\n",
            "kafka_2.13-3.8.0/libs/protobuf-java-3.23.4.jar\n",
            "kafka_2.13-3.8.0/libs/checker-qual-3.19.0.jar\n",
            "kafka_2.13-3.8.0/libs/error_prone_annotations-2.10.0.jar\n",
            "kafka_2.13-3.8.0/libs/kafka_2.13-3.8.0.jar\n",
            "kafka_2.13-3.8.0/site-docs/\n",
            "kafka_2.13-3.8.0/site-docs/kafka_2.13-3.8.0-site-docs.tgz\n",
            "kafka_2.13-3.8.0/libs/kafka-tools-3.8.0.jar\n",
            "kafka_2.13-3.8.0/libs/connect-runtime-3.8.0.jar\n",
            "kafka_2.13-3.8.0/libs/kafka-log4j-appender-3.8.0.jar\n",
            "kafka_2.13-3.8.0/libs/connect-json-3.8.0.jar\n",
            "kafka_2.13-3.8.0/libs/connect-transforms-3.8.0.jar\n",
            "kafka_2.13-3.8.0/libs/connect-api-3.8.0.jar\n",
            "kafka_2.13-3.8.0/libs/jackson-jaxrs-json-provider-2.16.2.jar\n",
            "kafka_2.13-3.8.0/libs/jackson-module-jaxb-annotations-2.16.2.jar\n",
            "kafka_2.13-3.8.0/libs/jackson-jaxrs-base-2.16.2.jar\n",
            "kafka_2.13-3.8.0/libs/jackson-module-afterburner-2.16.2.jar\n",
            "kafka_2.13-3.8.0/libs/reflections-0.10.2.jar\n",
            "kafka_2.13-3.8.0/libs/slf4j-reload4j-1.7.36.jar\n",
            "kafka_2.13-3.8.0/libs/reload4j-1.2.25.jar\n",
            "kafka_2.13-3.8.0/libs/jakarta.xml.bind-api-2.3.3.jar\n",
            "kafka_2.13-3.8.0/libs/jakarta.activation-api-1.2.2.jar\n",
            "kafka_2.13-3.8.0/libs/jersey-container-servlet-2.39.1.jar\n",
            "kafka_2.13-3.8.0/libs/jersey-hk2-2.39.1.jar\n",
            "kafka_2.13-3.8.0/libs/jaxb-api-2.3.1.jar\n",
            "kafka_2.13-3.8.0/libs/activation-1.1.1.jar\n",
            "kafka_2.13-3.8.0/libs/jetty-servlet-9.4.54.v20240208.jar\n",
            "kafka_2.13-3.8.0/libs/jetty-security-9.4.54.v20240208.jar\n",
            "kafka_2.13-3.8.0/libs/jetty-server-9.4.54.v20240208.jar\n",
            "kafka_2.13-3.8.0/libs/jetty-servlets-9.4.54.v20240208.jar\n",
            "kafka_2.13-3.8.0/libs/jetty-client-9.4.54.v20240208.jar\n",
            "kafka_2.13-3.8.0/libs/maven-artifact-3.9.6.jar\n",
            "kafka_2.13-3.8.0/libs/swagger-annotations-2.2.8.jar\n",
            "kafka_2.13-3.8.0/libs/javax.ws.rs-api-2.1.1.jar\n",
            "kafka_2.13-3.8.0/libs/jersey-container-servlet-core-2.39.1.jar\n",
            "kafka_2.13-3.8.0/libs/jersey-server-2.39.1.jar\n",
            "kafka_2.13-3.8.0/libs/jersey-client-2.39.1.jar\n",
            "kafka_2.13-3.8.0/libs/jersey-common-2.39.1.jar\n",
            "kafka_2.13-3.8.0/libs/jakarta.ws.rs-api-2.1.6.jar\n",
            "kafka_2.13-3.8.0/libs/hk2-locator-2.6.1.jar\n",
            "kafka_2.13-3.8.0/libs/javassist-3.29.2-GA.jar\n",
            "kafka_2.13-3.8.0/libs/javax.activation-api-1.2.0.jar\n",
            "kafka_2.13-3.8.0/libs/javax.servlet-api-3.1.0.jar\n",
            "kafka_2.13-3.8.0/libs/jetty-http-9.4.54.v20240208.jar\n",
            "kafka_2.13-3.8.0/libs/jetty-io-9.4.54.v20240208.jar\n",
            "kafka_2.13-3.8.0/libs/jetty-util-ajax-9.4.54.v20240208.jar\n",
            "kafka_2.13-3.8.0/libs/jetty-continuation-9.4.54.v20240208.jar\n",
            "kafka_2.13-3.8.0/libs/jetty-util-9.4.54.v20240208.jar\n",
            "kafka_2.13-3.8.0/libs/jsr305-3.0.2.jar\n",
            "kafka_2.13-3.8.0/libs/plexus-utils-3.5.1.jar\n",
            "kafka_2.13-3.8.0/libs/commons-lang3-3.12.0.jar\n",
            "kafka_2.13-3.8.0/libs/hk2-api-2.6.1.jar\n",
            "kafka_2.13-3.8.0/libs/hk2-utils-2.6.1.jar\n",
            "kafka_2.13-3.8.0/libs/jakarta.inject-2.6.1.jar\n",
            "kafka_2.13-3.8.0/libs/jakarta.annotation-api-1.3.5.jar\n",
            "kafka_2.13-3.8.0/libs/osgi-resource-locator-1.0.3.jar\n",
            "kafka_2.13-3.8.0/libs/jakarta.validation-api-2.0.2.jar\n",
            "kafka_2.13-3.8.0/libs/aopalliance-repackaged-2.6.1.jar\n",
            "kafka_2.13-3.8.0/libs/trogdor-3.8.0.jar\n",
            "kafka_2.13-3.8.0/libs/kafka-shell-3.8.0.jar\n",
            "kafka_2.13-3.8.0/libs/jline-3.25.1.jar\n",
            "kafka_2.13-3.8.0/libs/connect-file-3.8.0.jar\n",
            "kafka_2.13-3.8.0/libs/connect-basic-auth-extension-3.8.0.jar\n",
            "kafka_2.13-3.8.0/libs/javax.annotation-api-1.3.2.jar\n",
            "kafka_2.13-3.8.0/libs/connect-mirror-3.8.0.jar\n",
            "kafka_2.13-3.8.0/libs/connect-mirror-client-3.8.0.jar\n",
            "kafka_2.13-3.8.0/libs/kafka-streams-3.8.0.jar\n",
            "kafka_2.13-3.8.0/libs/rocksdbjni-7.9.2.jar\n",
            "kafka_2.13-3.8.0/libs/kafka-streams-scala_2.13-3.8.0.jar\n",
            "kafka_2.13-3.8.0/libs/kafka-streams-test-utils-3.8.0.jar\n",
            "kafka_2.13-3.8.0/libs/kafka-streams-examples-3.8.0.jar\n"
          ]
        }
      ],
      "source": [
        "# Descompactando o kafka e criando um link para a pasta do kafka\n",
        "!tar xvfz kafka_2.13-3.8.0.tgz\n",
        "!ln -s kafka_2.13-3.8.0 kafka\n",
        "!rm kafka_2.13-3.8.0.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRkpYLef_HJ7"
      },
      "outputs": [],
      "source": [
        "# Ativando os daemons do kafka...\n",
        "!./kafka/bin/zookeeper-server-start.sh -daemon ./kafka/config/zookeeper.properties\n",
        "!./kafka/bin/kafka-server-start.sh -daemon ./kafka/config/server.properties"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1a66040",
        "outputId": "a83a8a3b-e6c4-4baa-ed9a-3fd51b80e951"
      },
      "source": [
        "# Check if Kafka is running by listing topics\n",
        "!./kafka/bin/kafka-topics.sh --list --bootstrap-server localhost:9092"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/kafka/bin/kafka-run-class.sh: line 353: /usr/lib/jvm/java-11-openjdk-amd64/bin/java: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!jps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvUcBPj_DX7D",
        "outputId": "b45a5f9a-47af-4173-a013-7c8c12f43188"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2077 Jps\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7jQ2ISQ_Thl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b91c412-dd68-4fa7-ee02-b8634813b8b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/kafka/bin/kafka-run-class.sh: line 353: /usr/lib/jvm/java-11-openjdk-amd64/bin/java: No such file or directory\n",
            "/content/kafka/bin/kafka-run-class.sh: line 353: /usr/lib/jvm/java-11-openjdk-amd64/bin/java: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "#Criando canais kafka\n",
        "!./kafka/bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic canalinput\n",
        "!./kafka/bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic canaloutput"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8NBc57xo2k5"
      },
      "source": [
        "# 4. Contabilizando as palavras do kafka no streaming\n",
        "\n",
        "1.   Item da lista\n",
        "2.   Item da lista\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmVPG6dGZB8r"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmiGmlq0ZJdb"
      },
      "outputs": [],
      "source": [
        "SPARK_MASTER=\"spark://localhost:7077\"\n",
        "APP_NAME=\"Lab Kafka Niajus\"\n",
        "\n",
        "KAFKA_HOST=\"localhost:9092\"\n",
        "KAFKA_TOPIC_IN=\"canalinput\"\n",
        "KAFKA_TOPIC_OUT=\"canaloutput\"\n",
        "\n",
        "INTERVAL = \"5 seconds\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4cm2RuyZMMy"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.master(SPARK_MASTER).appName(APP_NAME).getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NGROK_HOST = \"9af2b399ddd8.ngrok-free.app\"\n",
        "ES_INDEX = \"spark_word_counts\"\n",
        "\n",
        "def write_to_es(df):\n",
        "    \"\"\"Escreve cada micro-batch no Elasticsearch através do túnel ngrok.\"\"\"\n",
        "    # O ngrok tunnel para a porta 9200 é tipicamente na porta 443 se for HTTPS\n",
        "    (df.write.format(\"org.elasticsearch.spark.sql\")\n",
        "        .option(\"es.resource\", f\"{ES_INDEX}/_doc\")\n",
        "        .option(\"es.nodes\", NGROK_HOST)\n",
        "        .option(\"es.port\", \"443\") # Use a porta padrão HTTPS, pois ngrok usa HTTPS por padrão\n",
        "        .option(\"es.net.ssl\", \"true\") # Habilita SSL para a conexão ngrok HTTPS\n",
        "        .option(\"es.mapping.id\", \"word\")\n",
        "        .option(\"es.write.operation\", \"upsert\")\n",
        "        .mode(\"append\")\n",
        "        .save())"
      ],
      "metadata": {
        "id": "zvdJHCJkWAac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDVadrCeZP64"
      },
      "outputs": [],
      "source": [
        "messages = spark.readStream.format(\"kafka\").option(\"kafka.bootstrap.servers\", KAFKA_HOST) \\\n",
        "                .option (\"subscribe\", KAFKA_TOPIC_IN) \\\n",
        "                .option (\"includeTimestamp\", \"true\").load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLJnPrBOZP4S"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import explode, split, col, upper, window, to_json, struct, lit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Instalação da Biblioteca Hugging Face Datasets ---\n",
        "# Se ainda não estiver instalado no seu ambiente:\n",
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFD734KlXw25",
        "outputId": "9645a9af-f8d3-48ac-8507-073c3b56bd06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:kafka.coordinator.heartbeat:Heartbeat failed for group my-word-count-group because it is rebalancing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.10.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:kafka.coordinator.heartbeat:Heartbeat failed for group my-word-count-group because it is rebalancing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Producer do Kafka para mandar os textos do ImDB que são puxados de datasets do Huggingface"
      ],
      "metadata": {
        "id": "I_fhUZHQP9NL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d3d0fad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0d6d270-d388-4872-a149-258a5960f9b7"
      },
      "source": [
        "# --- 2. Imports e Configuração do Kafka ---\n",
        "from kafka import KafkaProducer\n",
        "import time\n",
        "from datasets import load_dataset\n",
        "import random # Para selecionar um split aleatório ou embaralhar\n",
        "\n",
        "# Configuração do Producer\n",
        "producer = KafkaProducer(bootstrap_servers=['localhost:9092'],\n",
        "                         value_serializer=lambda v: v.encode('utf-8'))\n",
        "\n",
        "# Função para enviar a mensagem\n",
        "def send_message(topic, message):\n",
        "    # Envia apenas o início da mensagem para não sobrecarregar o log\n",
        "    display_message = message[:100].replace('\\n', ' ') + '...'\n",
        "\n",
        "    producer.send(topic, message)\n",
        "    producer.flush()\n",
        "    print(f\"Sent: '{display_message}' to topic '{topic}'\")\n",
        "\n",
        "print(\"Starting Kafka producer for 'canalinput'...\")\n",
        "\n",
        "# --- 3. Carregamento e Processamento do Dataset ---\n",
        "\n",
        "# Carrega o dataset IMDb do Hugging Face.\n",
        "# O dataset tem 3 splits: 'train', 'test' e 'unsupervised'. Usaremos o 'train'.\n",
        "print(\"Loading IMDb dataset from Hugging Face...\")\n",
        "try:\n",
        "    imdb_dataset = load_dataset(\"imdb\", split=\"train\")\n",
        "\n",
        "    # Define o número de reviews que você quer enviar (ex: 10 mensagens)\n",
        "    NUM_MESSAGES_TO_SEND = 200\n",
        "\n",
        "    # Seleciona as primeiras N mensagens para evitar carregar o dataset inteiro\n",
        "    messages_to_send = imdb_dataset.select(range(NUM_MESSAGES_TO_SEND))\n",
        "\n",
        "    # --- 4. Envio das Mensagens ---\n",
        "    print(f\"Starting to send {NUM_MESSAGES_TO_SEND} movie reviews to 'canalinput'...\")\n",
        "\n",
        "    # Itera sobre os exemplos e envia o campo 'text'\n",
        "    for review in messages_to_send:\n",
        "        # O campo 'text' contém a review do filme\n",
        "        msg = review['text']\n",
        "        send_message('canalinput', msg)\n",
        "        time.sleep(0.1) # Intervalo de 1 segundo entre mensagens para simular streaming\n",
        "\n",
        "    print(\"Finished sending messages.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading or sending the dataset: {e}\")\n",
        "    print(\"Please ensure you have an active internet connection and the 'datasets' library is installed.\")\n",
        "\n",
        "# Fecha o producer após o uso\n",
        "producer.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Kafka producer for 'canalinput'...\n",
            "Loading IMDb dataset from Hugging Face...\n",
            "Starting to send 200 movie reviews to 'canalinput'...\n",
            "Sent: 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it w...' to topic 'canalinput'\n",
            "Sent: '\"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn't matter what one's poli...' to topic 'canalinput'\n",
            "Sent: 'If only to avoid making this type of film in the future. This film is interesting as an experiment b...' to topic 'canalinput'\n",
            "Sent: 'This film was probably inspired by Godard's Masculin, féminin and I urge you to see that film instea...' to topic 'canalinput'\n",
            "Sent: 'Oh, brother...after hearing about this ridiculous film for umpteen years all I can think of is that ...' to topic 'canalinput'\n",
            "Sent: 'I would put this at the top of my list of films in the category of unwatchable trash! There are film...' to topic 'canalinput'\n",
            "Sent: 'Whoever wrote the screenplay for this movie obviously never consulted any books about Lucille Ball, ...' to topic 'canalinput'\n",
            "Sent: 'When I first saw a glimpse of this movie, I quickly noticed the actress who was playing the role of ...' to topic 'canalinput'\n",
            "Sent: 'Who are these \"They\"- the actors? the filmmakers? Certainly couldn't be the audience- this is among ...' to topic 'canalinput'\n",
            "Sent: 'This is said to be a personal film for Peter Bogdonavitch. He based it on his life but changed thing...' to topic 'canalinput'\n",
            "Sent: 'It was great to see some of my favorite stars of 30 years ago including John Ritter, Ben Gazarra and...' to topic 'canalinput'\n",
            "Sent: 'I can't believe that those praising this movie herein aren't thinking of some other film. I was prep...' to topic 'canalinput'\n",
            "Sent: 'Never cast models and Playboy bunnies in your films! Bob Fosse's \"Star 80\" about Dorothy Stratten, o...' to topic 'canalinput'\n",
            "Sent: 'Its not the cast. A finer group of actors, you could not find. Its not the setting. The director is ...' to topic 'canalinput'\n",
            "Sent: 'Today I found \"They All Laughed\" on VHS on sale in a rental. It was a really old and very used VHS, ...' to topic 'canalinput'\n",
            "Sent: 'This film is just plain horrible. John Ritter doing pratt falls, 75% of the actors delivering their ...' to topic 'canalinput'\n",
            "Sent: 'My interest in Dorothy Stratten caused me to purchase this video. Although it had great actors/actre...' to topic 'canalinput'\n",
            "Sent: 'I have this film out of the library right now and I haven't finished watching it. It is so bad I am ...' to topic 'canalinput'\n",
            "Sent: 'I think I will make a movie next weekend. Oh wait, I'm working..oh I'm sure I can fit it in. It look...' to topic 'canalinput'\n",
            "Sent: 'Pros: Nothing<br /><br />Cons: Everything<br /><br />Plot summary: A female reporter runs into a hit...' to topic 'canalinput'\n",
            "Sent: 'If the crew behind \"Zombie Chronicles\" ever read this, here's some advice guys: <br /><br />1. In a ...' to topic 'canalinput'\n",
            "Sent: '1st watched 8/3/2003 - 2 out of 10(Dir-Brad Sykes): Mindless 3-D movie about flesh-eating zombies in...' to topic 'canalinput'\n",
            "Sent: 'There's tons of good-looking women in this flick. But alas, this movie is nudity-free. Grrrrrrrrrr S...' to topic 'canalinput'\n",
            "Sent: 'En route to a small town that lays way off the beaten track (but which looks suspiciously close to a...' to topic 'canalinput'\n",
            "Sent: 'Without wishing to be a killjoy, Brad Sykes is responsible for at least two of the most dull and cli...' to topic 'canalinput'\n",
            "Sent: 'My girlfriend once brought around The Zombie Chronicles for us to watch as a joke. Little did we rea...' to topic 'canalinput'\n",
            "Sent: 'Amateur, no budget films can be surprisingly good ... this however is not one of them.<br /><br />Ah...' to topic 'canalinput'\n",
            "Sent: 'OK its not the best film I've ever seen but at the same time I've been able to sit and watch it TWIC...' to topic 'canalinput'\n",
            "Sent: 'Some films that you pick up for a pound turn out to be rather good - 23rd Century films released doz...' to topic 'canalinput'\n",
            "Sent: 'I received this movie as a gift, I knew from the DVD cover, this movie are going to be bad.After not...' to topic 'canalinput'\n",
            "Sent: 'I have not seen many low budget films i must admit, but this is the worst movie ever probably, the m...' to topic 'canalinput'\n",
            "Sent: '..Oh wait, I can! This movie is not for the typical film snob, unless you want to brush up on your t...' to topic 'canalinput'\n",
            "Sent: 'You have to admire Brad Sykes even if you don't particularly want to, a man who churns out budget ho...' to topic 'canalinput'\n",
            "Sent: 'THE ZOMBIE CHRONICLES <br /><br />Aspect ratio: 1.33:1 (Nu-View 3-D)<br /><br />Sound format: Mono<b...' to topic 'canalinput'\n",
            "Sent: 'A woman asks for advice on the road to reach a mysterious town, and hears two ghoulish stories from ...' to topic 'canalinput'\n",
            "Sent: 'Really, I can't believe that I spent $5 on this movie. I am a huge zombie fanatic and thought the mo...' to topic 'canalinput'\n",
            "Sent: 'I rented this movie about 3 years ago, and it still stands out in my mind as the worst movie ever ma...' to topic 'canalinput'\n",
            "Sent: ':Spoilers:<br /><br />I was very disappointed in Love's Abiding Joy. I had been waiting a really lon...' to topic 'canalinput'\n",
            "Sent: 'I've seen all four of the movies in this series. Each one strays further and further from the books....' to topic 'canalinput'\n",
            "Sent: 'I very much looked forward to this movie. Its a good family movie; however, if Michael Landon Jr.'s ...' to topic 'canalinput'\n",
            "Sent: 'I have read all of the Love Come Softly books. Knowing full well that movies can not use all aspects...' to topic 'canalinput'\n",
            "Sent: 'As a Southern Baptist, it pains me that I must give a below average rating to an overtly Christian m...' to topic 'canalinput'\n",
            "Sent: 'WARNING: This review contains SPOILERS. Do not read if you don't want some points revealed to you be...' to topic 'canalinput'\n",
            "Sent: 'As a kid I did think the weapon the murderer wielded was cool, however I was a kid and so I was a bi...' to topic 'canalinput'\n",
            "Sent: 'Jill Dunne (played by Mitzi Kapture), is an attractive, nice woman, over-whelmed by a smart-mouthed ...' to topic 'canalinput'\n",
            "Sent: 'This movie sucked. It really was a waste of my life. The acting was atrocious, the plot completely i...' to topic 'canalinput'\n",
            "Sent: 'Lifetime did it again. Can we say stupid? I couldn't wait for it to end. The plot was senseless. The...' to topic 'canalinput'\n",
            "Sent: 'I have to say I am really surprised at the high ratings for this movie. I found it to be absolutely ...' to topic 'canalinput'\n",
            "Sent: 'The original book of this was set in the 1950s but that won't do for the TV series because most peop...' to topic 'canalinput'\n",
            "Sent: 'The annoying mouse and lullaby really got to me and really had nothing to do with the story...It's s...' to topic 'canalinput'\n",
            "Sent: 'I saw this film opening weekend in Australia, anticipating with an excellent cast of Ledger, Edgerto...' to topic 'canalinput'\n",
            "Sent: 'I saw this at the premiere in Melbourne<br /><br />It is shallow, two-dimensional, unaffecting and, ...' to topic 'canalinput'\n",
            "Sent: 'Ned Kelly (Ledger), the infamous Australian outlaw and legend. Sort of like Robin Hood, with a mix o...' to topic 'canalinput'\n",
            "Sent: 'They constructed this one as a kind of fantasy Man From Snowy River meets Butch Cassidy and the Sund...' to topic 'canalinput'\n",
            "Sent: 'This has to be the worst piece of garbage I've seen in a while.<br /><br />Heath Ledger is a heartth...' to topic 'canalinput'\n",
            "Sent: 'If the term itself were not geographically and semantically meaningless, one might well refer to \"Ne...' to topic 'canalinput'\n",
            "Sent: 'This movie was so unrelentingly bad, I could hardly believe I was watching it. The directing, editin...' to topic 'canalinput'\n",
            "Sent: 'This movie never made it to theaters in our area, so when it became available on DVD I was one of th...' to topic 'canalinput'\n",
            "Sent: 'I thought this was a very clunky, uninvolving version of a famous Australian story. Heath Ledger and...' to topic 'canalinput'\n",
            "Sent: 'Ned aKelly is such an important story to Australians but this movie is awful. It's an Australian sto...' to topic 'canalinput'\n",
            "Sent: 'From the very beginning, the political theme of this film is so obvious and heavy handed, that the o...' to topic 'canalinput'\n",
            "Sent: 'I guess I was attracted to this film both because of the sound of the story and the leading actor, s...' to topic 'canalinput'\n",
            "Sent: 'I don't quite get the rating for The Amati Girls and I think I was REALLY kind giving it a 4 out of ...' to topic 'canalinput'\n",
            "Sent: 'This movie was awful. The ending was absolutely horrible. There was no plot to the movie whatsoever....' to topic 'canalinput'\n",
            "Sent: 'Holy crap. This was the worst film I have seen in a long time. All the performances are fine, but th...' to topic 'canalinput'\n",
            "Sent: 'SWING! is an important film because it's one of the remaining Black-produced and acted films from th...' to topic 'canalinput'\n",
            "Sent: 'There's not a drop of sunshine in \"The Sunshine Boys\", which makes the title of this alleged comedy ...' to topic 'canalinput'\n",
            "Sent: 'I like Goldie Hawn and wanted another one of her films, so when I saw Protocol for $5.50 at Walmart ...' to topic 'canalinput'\n",
            "Sent: 'Protocol is an implausible movie whose only saving grace is that it stars Goldie Hawn along with a g...' to topic 'canalinput'\n",
            "Sent: 'When an attempt is made to assassinate the Emir of Ohtar, an Arab potentate visiting Washington, D.C...' to topic 'canalinput'\n",
            "Sent: 'What does the \" Executive producer \" do in a movie . If I remember correctly it's the person who rai...' to topic 'canalinput'\n",
            "Sent: 'Outlandish premise that rates low on plausibility and unfortunately also struggles feebly to raise l...' to topic 'canalinput'\n",
            "Sent: 'There are only two movies I would give a 1/10 to, this stinker and \"The Man who Fell to Earth.\" I re...' to topic 'canalinput'\n",
            "Sent: 'The only good thing about this movie was the shot of Goldie Hawn standing in her little french cut b...' to topic 'canalinput'\n",
            "Sent: 'I'm studying Catalan, and was delighted to find El Mar, a movie with mostly Catalan dialogue, at my ...' to topic 'canalinput'\n",
            "Sent: 'I was excited to view a Cataluña´s film in the Berlin´s competition. But after the presentation I wa...' to topic 'canalinput'\n",
            "Sent: 'this film was a major letdown. the level of relentless cruelty and violence in this film was very di...' to topic 'canalinput'\n",
            "Sent: 'Three part \"horror\" film with some guy in a boarded up house imploring the viewer not to go \"out the...' to topic 'canalinput'\n",
            "Sent: 'A very cheesy and dull road movie, with the intention to be hip and modern, shown in the editing sty...' to topic 'canalinput'\n",
            "Sent: 'There are some nice shots in this film, it catches some of the landscapes with such a beautiful ligh...' to topic 'canalinput'\n",
            "Sent: 'When a man who doesn't have Alzheimer's can't remember how many films he's made, he probably is the ...' to topic 'canalinput'\n",
            "Sent: 'I have been looking for this film for ages because it is quite rare to find as it was one of the vid...' to topic 'canalinput'\n",
            "Sent: 'As the number of Video Nasties I've yet to see dwindles, this little pile of garbage popped up on my...' to topic 'canalinput'\n",
            "Sent: 'Not sure if I'm referring to those who labeled this a video nasty or to the director...\"Devil Hunter...' to topic 'canalinput'\n",
            "Sent: 'This video nasty was initially banned in Britain, and allowed in last November without cuts.<br /><b...' to topic 'canalinput'\n",
            "Sent: 'Of the three titles from Jess Franco to find their way onto the Official DPP Video Nasty list (Devil...' to topic 'canalinput'\n",
            "Sent: 'How can you tell that a horror movie is terrible? when you can't stop laughing about it of course! T...' to topic 'canalinput'\n",
            "Sent: 'A model named Laura is working in South America when she is kidnapped from her hotel room by a gang ...' to topic 'canalinput'\n",
            "Sent: 'An actress making a movie in Africa is kidnapped and taken into the jungle where she is held for ran...' to topic 'canalinput'\n",
            "Sent: 'or anyone who was praying for the sight of Al Cliver wrestling a naked, 7ft tall black guy into a fu...' to topic 'canalinput'\n",
            "Sent: 'Devil Hunter gained notoriety for the fact that it's on the DPP 'Video Nasty' list, but it really ne...' to topic 'canalinput'\n",
            "Sent: 'This film seemed way too long even at only 75 minutes. The problem with jungle horror films is that ...' to topic 'canalinput'\n",
            "Sent: 'Sexo Cannibal, or Devil Hunter as it's more commonly known amongst English speaking audiences, start...' to topic 'canalinput'\n",
            "Sent: 'Not only is it a disgustingly made low-budget bad-acted movie, but the plot itself is just STUPID!!!...' to topic 'canalinput'\n",
            "Sent: 'This is the worst thing the TMNT franchise has ever spawned. I was a kid when this came out and I st...' to topic 'canalinput'\n",
            "Sent: 'Sometime in 1998, Saban had acquired the rights to produce a brand-new Ninja Turtles live-action ser...' to topic 'canalinput'\n",
            "Sent: 'This is the biggest insult to TMNT ever. Fortunantely, officially Venus does not exist in canon TMNT...' to topic 'canalinput'\n",
            "Sent: 'I did not like the idea of the female turtle at all since 1987 we knew the TMNT to be four brothers ...' to topic 'canalinput'\n",
            "Sent: 'I cannot stay indifferent to Lars van Trier's films. I consider 'Breaking the Waves' nothing less th...' to topic 'canalinput'\n",
            "Sent: 'This film is terrible. You don't really need to read this review further. If you are planning on wat...' to topic 'canalinput'\n",
            "Sent: 'Terrible movie. Nuff Said.<br /><br />These Lines are Just Filler. The movie was bad. Why I have to ...' to topic 'canalinput'\n",
            "Sent: 'Assuming this won't end up a straight-to-video release, I would have to say void this title at all c...' to topic 'canalinput'\n",
            "Sent: 'Sometimes a movie is so comprehensively awful it has a destructive effect on your morale. You begin ...' to topic 'canalinput'\n",
            "Sent: 'I have to congratulate the genius who approved this one. Edward Furlong, you're not as good as you t...' to topic 'canalinput'\n",
            "Sent: 'I rented this one on DVD without any prior knowledge. I was suspicious seeing Michael Madsen appeari...' to topic 'canalinput'\n",
            "Sent: 'I saw this DVD in my friends house and thought that this was a Turkish action movie with some Hollyw...' to topic 'canalinput'\n",
            "Sent: 'What was with all the Turkish actors? No offense but I thought it was all for nothing for all these ...' to topic 'canalinput'\n",
            "Sent: 'This movie was terrible. at first i just read the plot summary and it looked OK, so i watched it. Th...' to topic 'canalinput'\n",
            "Sent: 'I am a big fan of Arnold Vosloo. Finally seeing him as the star of a recent movie, not just a bit pa...' to topic 'canalinput'\n",
            "Sent: 'This is an art film that was either made in 1969 or 1972 (the National Film Preservation Foundation ...' to topic 'canalinput'\n",
            "Sent: 'Nine minutes of psychedelic, pulsating, often symmetric abstract images, are enough to drive anyone ...' to topic 'canalinput'\n",
            "Sent: 'There are lots of extremely good-looking people in this movie. That's probably the best thing about ...' to topic 'canalinput'\n",
            "Sent: 'This is it. This is the one. This is the worst movie ever made. Ever. It beats everything. I have ne...' to topic 'canalinput'\n",
            "Sent: 'There are times when finishing a film one wishes to have a refund for the time just spent. This was ...' to topic 'canalinput'\n",
            "Sent: 'Weak plot, predictable violence, only semi interesting characters. Like the writer (also one of the ...' to topic 'canalinput'\n",
            "Sent: 'All I could think of while watching this movie was B-grade slop. Many have spoken about it's redeemi...' to topic 'canalinput'\n",
            "Sent: 'If you look at Corey Large's information here on IMDb, apparently there's a movie called \"Reload\" in...' to topic 'canalinput'\n",
            "Sent: 'This film had a lot of promise, and the plot was relatively interesting, however the actors, directo...' to topic 'canalinput'\n",
            "Sent: 'This is one of the dumbest films, I've ever seen. It rips off nearly ever type of thriller and manag...' to topic 'canalinput'\n",
            "Sent: '6/10 Acting, not great but some good acting.<br /><br />4/10 Director, makes some stupid decisions f...' to topic 'canalinput'\n",
            "Sent: 'This is really a new low in entertainment. Even though there are a lot worse movies out.<br /><br />...' to topic 'canalinput'\n",
            "Sent: 'From the beginning of the movie, it gives the feeling the director is trying to portray something, w...' to topic 'canalinput'\n",
            "Sent: 'I basically skimmed through the movie but just enough to catch watch the plot was about. To tell you...' to topic 'canalinput'\n",
            "Sent: 'This fanciful horror flick has Vincent Price playing a mad magician that realizes his vocational tal...' to topic 'canalinput'\n",
            "Sent: 'If I had not read Pat Barker's 'Union Street' before seeing this film, I would have liked it. Unfort...' to topic 'canalinput'\n",
            "Sent: 'I saw the capsule comment said \"great acting.\" In my opinion, these are two great actors giving horr...' to topic 'canalinput'\n",
            "Sent: 'Robert DeNiro plays the most unbelievably intelligent illiterate of all time. This movie is so waste...' to topic 'canalinput'\n",
            "Sent: 'Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terri...' to topic 'canalinput'\n",
            "Sent: 'Are you familiar with concept of children's artwork? While it is not the greatest Picasso any three-...' to topic 'canalinput'\n",
            "Sent: 'Ah, Bait. How do I hate thee? Let me count the ways. 1. You try to be funny, but are corny and unenj...' to topic 'canalinput'\n",
            "Sent: 'The premise of the movie has been explained and if you've gotten this far you don't me to pretend th...' to topic 'canalinput'\n",
            "Sent: 'Uninspired direction leaves a decent cast stranded in a handsome but bland adaptation, in which dial...' to topic 'canalinput'\n",
            "Sent: 'I was sooooo excited to see this movie after finally reading the book this week. My 13 year old son ...' to topic 'canalinput'\n",
            "Sent: 'Having seen three other versions of the same film, I am afraid for me this is by far the weakest, pr...' to topic 'canalinput'\n",
            "Sent: 'Saw this movie in my English class this afternoon and was surprised by how bad this version was. Don...' to topic 'canalinput'\n",
            "Sent: 'When will the hurting stop? I never want to see another version of a Christmas Carol again. They kee...' to topic 'canalinput'\n",
            "Sent: 'It was 9:30 PM last night at my friend's camping trailer and we were so hyped to watch South Park (a...' to topic 'canalinput'\n",
            "Sent: 'This is blatantly a futuristic adaptation of Jules Verne's \"Mysterious Island\". The sound editing is...' to topic 'canalinput'\n",
            "Sent: 'Beyond a shadow of a doubt Mysterious Planet is one of the worst movies ever made, yet retains an af...' to topic 'canalinput'\n",
            "Sent: 'The silent one-panel cartoon Henry comes to Fleischer Studios, billed as \"The world's funniest human...' to topic 'canalinput'\n",
            "Sent: 'William Russ is the main character throughout this made for TV movie. He left his family behind to o...' to topic 'canalinput'\n",
            "Sent: 'From a poorly contrived plot line that makes almost no sense to bad dialogue and disjointed scenes t...' to topic 'canalinput'\n",
            "Sent: 'In director Sooraj Barjatya's Vivah,20-something Delhi boy Shahid Kapur finds himself smitten by the...' to topic 'canalinput'\n",
            "Sent: 'I never like to comment on a good film but when it comes to a bad movie, I gotta come really hard on...' to topic 'canalinput'\n",
            "Sent: 'I won't say this movie was bad, but it wasn't good either. I expected something good but I guess Hum...' to topic 'canalinput'\n",
            "Sent: 'A Cinderella story made for adults who live in dreamland. The romance is very unrealistic, fluttery,...' to topic 'canalinput'\n",
            "Sent: 'After being hugely entertained by Mr. Brosnan's performance as a cad in \"The Tailor of Panama\" (whic...' to topic 'canalinput'\n",
            "Sent: 'I very nearly walked out, but I'd paid my money, and my nearly-as-disgusted friend wanted to hold ou...' to topic 'canalinput'\n",
            "Sent: 'The fine cast cannot uplift this routine tale of a secretary murdered by her married paramour. In fa...' to topic 'canalinput'\n",
            "Sent: 'This film was choppy, incoherent and contrived. It was also an extremely mean-spirited portrayal of ...' to topic 'canalinput'\n",
            "Sent: 'This film is a calculated attempt to cash in the success of Sex in the City and Four Weddings and a ...' to topic 'canalinput'\n",
            "Sent: 'This had to be one of the worst films ever. When Kate shows up and Jed is with a bunch of guys and t...' to topic 'canalinput'\n",
            "Sent: 'This starts off bad, what with the three women acting like simpering junior high school wussies sitt...' to topic 'canalinput'\n",
            "Sent: 'This was awful. Andie Macdowell is a terrible actress. So wooden she makes a rocking horse look like...' to topic 'canalinput'\n",
            "Sent: 'Caught this on IFC yesterday, and can't believe the positive reviews! Am I the only one who thought ...' to topic 'canalinput'\n",
            "Sent: 'I thought it was a New-York located movie: wrong! It's a little British countryside setting.<br /><b...' to topic 'canalinput'\n",
            "Sent: 'Was this meant to be a comedy or a serious drama? This film starts with a light-hearted banter betwe...' to topic 'canalinput'\n",
            "Sent: 'Andie McDowell is beautiful as the 40-ish woman whose late start at a serious relationship leads her...' to topic 'canalinput'\n",
            "Sent: 'SPOILER: The young lover, Jed, is kicked out by the spinster, Kate (Andie McDowell), because she wro...' to topic 'canalinput'\n",
            "Sent: 'The worst thing about Crush is not that it's acted pretty bad, or that the plot is virtually non-exi...' to topic 'canalinput'\n",
            "Sent: 'Not a `woman film' but film for the gang. One of the worst films ever made by a male director about ...' to topic 'canalinput'\n",
            "Sent: 'As a single woman over 40, I found this film extremely insulting and demeaning to single women over ...' to topic 'canalinput'\n",
            "Sent: 'I was gifted with this movie as it had such a great premise, the friendship of three women bespoiled...' to topic 'canalinput'\n",
            "Sent: '\"The Crush\" is a pleasant enough 40-something friends romantic chick flick for the first two-thirds ...' to topic 'canalinput'\n",
            "Sent: 'it MIGHT have been a good movie if it had explored something more interesting rather than just the s...' to topic 'canalinput'\n",
            "Sent: '***LIGHT SPOILER ALERT*** The story sounds good and if you've read the novel, then you're probably e...' to topic 'canalinput'\n",
            "Sent: 'This is a movie that relies solely on the somewhat controversial image of incest and lesbianism to g...' to topic 'canalinput'\n",
            "Sent: 'I am not so much like Love Sick as I image. Finally the film express sexual relationship of Alex, ki...' to topic 'canalinput'\n",
            "Sent: 'I am not so much like Love Sick as I image. Finally the film express sexual relationship of Alex, ki...' to topic 'canalinput'\n",
            "Sent: 'Considering that this movie had a serious and quite successful launching campaign, I would have expe...' to topic 'canalinput'\n",
            "Sent: 'Yes, indeed, it could have been a good movie. A love biangle, (sorry for the poetical license, but i...' to topic 'canalinput'\n",
            "Sent: 'Closer to reality and containing more depth than \"Breakdance\", Stan Lathan's \"Beat Street\" is still ...' to topic 'canalinput'\n",
            "Sent: 'Hilariously obvious \"drama\" about a bunch of high school (I think) kids who enjoy non-stop hip-hop, ...' to topic 'canalinput'\n",
            "Sent: 'Maybe you shouldn't compare, but Wild Style and Style Wars are original Hip Hop. Beat Street does ha...' to topic 'canalinput'\n",
            "Sent: 'I could never stand watching Happy Days after Chachi joined the cast, so I knew I was in trouble whe...' to topic 'canalinput'\n",
            "Sent: 'Horrible film with bits of the Ramones strewn about. Your worse than average 1970's/80's comedy form...' to topic 'canalinput'\n",
            "Sent: 'This movie is a 90 minute Ramones concert with brief periods of stupidity and absolute boredom. What...' to topic 'canalinput'\n",
            "Sent: 'I gave this film 2 stars only because Dominic Monaghan actually put effort through in his acting. Ev...' to topic 'canalinput'\n",
            "Sent: 'I jumped at the chance to view this movie uncut and uninterrupted, remembering rahs and raves for it...' to topic 'canalinput'\n",
            "Sent: 'The perfect murder is foiled when a wife(played by Mary Ellen Trainor, once the wife to director Rob...' to topic 'canalinput'\n",
            "Sent: 'Well, as Goethe once said, there really isn't any point in trying to pass a negative judgement that ...' to topic 'canalinput'\n",
            "Sent: 'That's not the sound of bees, that's the effect induced by watching this extremely long, extremely b...' to topic 'canalinput'\n",
            "Sent: 'Iberia is nice to see on TV. But why see this in silver screen? Lot of dance and music. If you like ...' to topic 'canalinput'\n",
            "Sent: 'That reviewers liked this movie surprises me. The plot is a muddle. The characters are wooden. Micha...' to topic 'canalinput'\n",
            "Sent: 'This is a terrible movie, terrible script, bad direction and nonsensical ending. Also, bad performan...' to topic 'canalinput'\n",
            "Sent: 'Burt Kennedy used to be a very good director, but you'd never know it by this lumbering mess. Not on...' to topic 'canalinput'\n",
            "Sent: 'While being a great James Arness western, this film has gone down as the worst Alamo film ever made....' to topic 'canalinput'\n",
            "Sent: 'This movie is flawed on many fronts. Like many before it, it portrays more of the mythology of the A...' to topic 'canalinput'\n",
            "Sent: 'Slow and riddled with inaccuracy. Over-looking its flaws this is still an interesting account of the...' to topic 'canalinput'\n",
            "Sent: 'This film, The Alamo:Thirteen Days to Glory, is utter rubbish. The acting is awful, it is far too pa...' to topic 'canalinput'\n",
            "Sent: 'The story by Norman Maclean is a masterwork; Redford's film is a mediocrity. He adds banal scenes of...' to topic 'canalinput'\n",
            "Sent: 'The only good part about this film is the beautiful scenery. This movie was long and boring. The min...' to topic 'canalinput'\n",
            "Sent: '... to not live in Montana and especially not to live there at the end of the 19th century.<br /><br...' to topic 'canalinput'\n",
            "Sent: 'I always felt that a good film should have a plot. This particular film was missing one, and I feel ...' to topic 'canalinput'\n",
            "Sent: 'This movie has beautiful scenery. Unfortunately it has no plot. In order to have a plot there must b...' to topic 'canalinput'\n",
            "Sent: 'This movie has beautiful scenery. Unfortunately it has no plot. In order to have a plot there must b...' to topic 'canalinput'\n",
            "Sent: 'Sorry, gave it a 1, which is the rating I give to movies on which I walk out or fall asleep. In this...' to topic 'canalinput'\n",
            "Sent: 'I didn't know whether to laugh or cry at this misrepresentation of Canadian history, particularly th...' to topic 'canalinput'\n",
            "Sent: 'The five or so really good westerns that Mann made are unequaled as an ensemble in Hollywood. Even J...' to topic 'canalinput'\n",
            "Sent: 'Mann photographs the Alberta Rocky Mountains in a superb fashion, and Jimmy Stewart and Walter Brenn...' to topic 'canalinput'\n",
            "Finished sending messages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q27pv5FBZP16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a91b86b6-1a09-4699-c903-c6e9bbec29fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:3: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:3: SyntaxWarning: invalid escape sequence '\\s'\n",
            "/tmp/ipython-input-911942699.py:3: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  explode(split(col(\"value\"), \"\\s+\")).alias(\"word\"),\n"
          ]
        }
      ],
      "source": [
        "words = messages \\\n",
        "            .select(\n",
        "                explode(split(col(\"value\"), \"\\s+\")).alias(\"word\"),\n",
        "                messages.timestamp\n",
        "        ).select (\n",
        "            upper(col(\"word\")).alias(\"word\"),\n",
        "            col(\"timestamp\")\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAmLlHCJZPzb"
      },
      "outputs": [],
      "source": [
        "wordCounts = words.withWatermark(\"timestamp\", INTERVAL) \\\n",
        "                .groupBy(\n",
        "                    window(words.timestamp, INTERVAL, INTERVAL), \"word\"\n",
        "                ).count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6QxUk_wZPxC"
      },
      "outputs": [],
      "source": [
        "wordCountsJson = wordCounts.select(\n",
        "    lit(\"1\").alias(\"key\"),\n",
        "    to_json(struct(\"word\", \"count\", 'window.start')).alias(\"value\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONh84yUeqco2"
      },
      "outputs": [],
      "source": [
        "wck = wordCountsJson.writeStream.outputMode(\"complete\").format(\"kafka\").option(\"kafka.bootstrap.servers\", KAFKA_HOST) \\\n",
        "        .option(\"topic\", KAFKA_TOPIC_OUT).option(\"checkpointLocation\", \"/tmp/spark-kafka\") \\\n",
        "        .trigger(processingTime=INTERVAL).start()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Consome as palavras e printa a palavra com seu respectivo count"
      ],
      "metadata": {
        "id": "o8yBWhx2PwDf"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfe5e02a"
      },
      "source": [
        "from kafka import KafkaConsumer\n",
        "import json\n",
        "\n",
        "# Configure the Kafka Consumer\n",
        "consumer = KafkaConsumer(\n",
        "    'canaloutput',\n",
        "    bootstrap_servers=['localhost:9092'],\n",
        "    auto_offset_reset='earliest',  # Start consuming from the beginning of the topic if no offset is committed\n",
        "    enable_auto_commit=True,       # Commit offsets automatically\n",
        "    group_id='my-word-count-group',# Consumer group ID\n",
        "    value_deserializer=lambda x: json.loads(x.decode('utf-8')) # Deserialize JSON messages\n",
        ")\n",
        "\n",
        "print(\"Starting Kafka consumer for 'canaloutput'...\")\n",
        "\n",
        "# Consume messages\n",
        "for message in consumer:\n",
        "    print(f\"Received message: Palavra '{message.value['word']}' -> Count: {message.value['count']}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjNFRTTsbD7w",
        "outputId": "a16e929f-bb2a-41bc-e5c3-39d0a318044a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from kafka import KafkaConsumer\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "import time\n",
        "from IPython.display import clear_output # Para limpar o output em ambientes como Jupyter/Colab\n",
        "\n",
        "# Dicionário para armazenar o estado das contagens de palavras\n",
        "word_counts_accumulator = defaultdict(int)\n",
        "\n",
        "# Contador para controlar a frequência de atualização do gráfico\n",
        "message_counter = 0\n",
        "UPDATE_FREQUENCY = 200 # Atualizar o gráfico a cada 50 novas mensagens\n",
        "\n",
        "# Configure o Kafka Consumer\n",
        "consumer = KafkaConsumer(\n",
        "    'canaloutput',\n",
        "    bootstrap_servers=['localhost:9092'],\n",
        "    auto_offset_reset='earliest',\n",
        "    enable_auto_commit=True,\n",
        "    group_id='my-word-count-group',\n",
        "    value_deserializer=lambda x: json.loads(x.decode('utf-8'))\n",
        ")\n",
        "\n",
        "def plot_word_counts(counts_dict, top_n=10):\n",
        "    \"\"\"Gera e exibe o gráfico de barras das palavras mais frequentes.\"\"\"\n",
        "\n",
        "    # Ordena as palavras pela contagem (do maior para o menor)\n",
        "    sorted_words = sorted(counts_dict.items(), key=lambda item: item[1], reverse=True)\n",
        "\n",
        "    # Seleciona as N palavras mais frequentes\n",
        "    top_words = sorted_words[:top_n]\n",
        "\n",
        "    # Prepara os dados para o Matplotlib\n",
        "    words = [item[0] for item in top_words]\n",
        "    counts = [item[1] for item in top_words]\n",
        "\n",
        "    # Cria o gráfico\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.barh(words[::-1], counts[::-1], color='skyblue') # barh para barras horizontais\n",
        "    plt.xlabel('Contagem Acumulada')\n",
        "    plt.title(f'Top {top_n} Palavras mais Frequentes (Atualizado)')\n",
        "\n",
        "    # Exibir o gráfico\n",
        "    plt.show()\n",
        "\n",
        "print(\"Starting Kafka consumer for 'canaloutput' and initializing word count graph...\")\n",
        "\n",
        "# Consome mensagens\n",
        "try:\n",
        "    for message in consumer:\n",
        "\n",
        "        # 1. Processa a mensagem\n",
        "        data = message.value\n",
        "        word = data['word']\n",
        "        count = data['count']\n",
        "\n",
        "        # O Spark Structured Streaming no modo \"update\" envia o NOVO total da contagem\n",
        "        # Apenas atualizamos o dicionário com o valor mais recente\n",
        "        word_counts_accumulator[word] = count\n",
        "\n",
        "        # Imprime a atualização para o console (opcional)\n",
        "        print(f\"Received update: Palavra '{word}' -> Count: {count}\")\n",
        "\n",
        "        # 2. Atualiza o contador e gera o gráfico\n",
        "        message_counter += 1\n",
        "\n",
        "        if message_counter % UPDATE_FREQUENCY == 0:\n",
        "            clear_output(wait=True) # Limpa o output anterior (útil no Colab/Jupyter)\n",
        "            print(f\"--- Atualizando Gráfico (Total de {message_counter} mensagens processadas) ---\")\n",
        "            plot_word_counts(word_counts_accumulator)\n",
        "            time.sleep(1) # Pequena pausa para visualização\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\nConsumer stopped by user. Generating final plot...\")\n",
        "    plot_word_counts(word_counts_accumulator)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nAn error occurred: {e}\")\n",
        "\n",
        "finally:\n",
        "    consumer.close()"
      ],
      "metadata": {
        "id": "dy5D9EznJH8R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a6ae0327-0568-49ea-ff5f-670399b5d57e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Atualizando Gráfico (Total de 26350 mensagens processadas) ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Consumer stopped by user. Generating final plot...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEvyhVxOz-Oy"
      },
      "source": [
        "# Exercício\n",
        "\n",
        "A. Perceba que o resultado do canal de saída (canaloutput) não é uma contabilização das palavras de entrada... Altere o notebook para que o canal de saída contemple valores acumulados das palavras (contador de palavras).\n",
        "\n",
        "B. Crie um outro notebook, similar ao notebook, porém promovendo as seguintes alterações:\n",
        "<ol>\n",
        "  <li> Conectar uma nuvem de palavras (em forma gráfica) no canal de saída  <p>\n",
        "\n",
        "  <li> Conectar uma fonte alternativa de dados, preferencialmente online, ao canal de entrada. Por exemplo, ler dados de uma rede social ou de dois arquivos simultâneos (enfim, gerar alguma variação do notebook apresentado <p>\n",
        "</ol>\n",
        "As respostas desse experimento exercício devem ser postadas no Moodle em data especificada pelo professor."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementaçãop Kibana e ElasticSearch\n",
        "\n",
        "- Problemas no modo local\n",
        "- Conectar os dois (Kibana e ElasticSeach)\n",
        "- Só consegui rodar no Google Colab\n"
      ],
      "metadata": {
        "id": "j-Lu1XKwQrL2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AZ9dKqBwQ4MV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "_A4TOivc6gBd",
        "Q2A-iRLR-Y3E",
        "H8NBc57xo2k5"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}